{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52cfa135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install via terminal in ubuntu\n",
    "# sudo apt install pip\n",
    "# pip install scikit-learn pandas seaborn tensorflow scikeras\n",
    "# !pip install keras-tuner --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7a5c8fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'local[*]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sc master - running locally\n",
    "sc.master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b84fce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcf71413",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-08 17:38:13.880129: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-08 17:38:14.008393: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-08 17:38:14.008418: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-08 17:38:14.008443: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-08 17:38:14.114372: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-08 17:38:14.115044: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-08 17:38:15.026187: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04f8560",
   "metadata": {},
   "source": [
    "## Data reading and final cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d636740c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-08 17:38:20,588 WARN util.package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>status</th>\n",
       "      <th>runtime</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release_year</th>\n",
       "      <th>genre_count</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Family</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>History</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Music</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Science Fiction</th>\n",
       "      <th>TV Movie</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Inception</td>\n",
       "      <td>8.364</td>\n",
       "      <td>Released</td>\n",
       "      <td>148</td>\n",
       "      <td>83.952</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Interstellar</td>\n",
       "      <td>8.417</td>\n",
       "      <td>Released</td>\n",
       "      <td>169</td>\n",
       "      <td>140.241</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>8.512</td>\n",
       "      <td>Released</td>\n",
       "      <td>152</td>\n",
       "      <td>130.643</td>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Avatar</td>\n",
       "      <td>7.573</td>\n",
       "      <td>Released</td>\n",
       "      <td>162</td>\n",
       "      <td>79.932</td>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Avengers</td>\n",
       "      <td>7.71</td>\n",
       "      <td>Released</td>\n",
       "      <td>143</td>\n",
       "      <td>98.082</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             title vote_average    status runtime popularity release_year  \\\n",
       "0        Inception        8.364  Released     148     83.952         2010   \n",
       "1     Interstellar        8.417  Released     169    140.241         2014   \n",
       "2  The Dark Knight        8.512  Released     152    130.643         2008   \n",
       "3           Avatar        7.573  Released     162     79.932         2009   \n",
       "4     The Avengers         7.71  Released     143     98.082         2012   \n",
       "\n",
       "  genre_count  Action Adventure  Animation  Comedy  Crime  Documentary  Drama  \\\n",
       "0           3     1.0         1          0     0.0      0            0      0   \n",
       "1           3     0.0         1          0     0.0      0            0      1   \n",
       "2           4     1.0         0          0     0.0      1            0      1   \n",
       "3           4     1.0         1          0     0.0      0            0      0   \n",
       "4           3     1.0         1          0     0.0      0            0      0   \n",
       "\n",
       "   Family  Fantasy  History  Horror  Music  Mystery  Romance  Science Fiction  \\\n",
       "0       0        0        0       0      0        0        0                1   \n",
       "1       0        0        0       0      0        0        0                1   \n",
       "2       0        0        0       0      0        0        0                0   \n",
       "3       0        1        0       0      0        0        0                1   \n",
       "4       0        0        0       0      0        0        0                1   \n",
       "\n",
       "   TV Movie  Thriller  War  Western  \n",
       "0         0         0    0        0  \n",
       "1         0         0    0        0  \n",
       "2         0         1    0        0  \n",
       "3         0         0    0        0  \n",
       "4         0         0    0        0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the cleaned dataset from hadoop. \n",
    "# This has been renamed from part-00000-cdda873a-60d8-4ecc-b275-06323eb00068-c000.csv to cleaned_TMBD_dataset\n",
    "dataPath = \"/CA1/data/cleaned/cleaned_TMDB_dataset.csv\"\n",
    "cleanedDF = spark.read \\\n",
    "    .option(\"multiline\", \"true\") \\\n",
    "    .option(\"quote\", '\"') \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"escape\", \"\\\\\") \\\n",
    "    .option(\"escape\", '\"') \\\n",
    "    .csv(dataPath, header = True, inferSchema = True)\n",
    "cleanedDF.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6886029",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- vote_average: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- runtime: string (nullable = true)\n",
      " |-- popularity: string (nullable = true)\n",
      " |-- release_year: string (nullable = true)\n",
      " |-- genre_count: string (nullable = true)\n",
      " |-- Action: double (nullable = true)\n",
      " |-- Adventure: string (nullable = true)\n",
      " |-- Animation: integer (nullable = true)\n",
      " |-- Comedy: double (nullable = true)\n",
      " |-- Crime: integer (nullable = true)\n",
      " |-- Documentary: integer (nullable = true)\n",
      " |-- Drama: integer (nullable = true)\n",
      " |-- Family: integer (nullable = true)\n",
      " |-- Fantasy: integer (nullable = true)\n",
      " |-- History: integer (nullable = true)\n",
      " |-- Horror: integer (nullable = true)\n",
      " |-- Music: integer (nullable = true)\n",
      " |-- Mystery: integer (nullable = true)\n",
      " |-- Romance: integer (nullable = true)\n",
      " |-- Science Fiction: integer (nullable = true)\n",
      " |-- TV Movie: integer (nullable = true)\n",
      " |-- Thriller: integer (nullable = true)\n",
      " |-- War: integer (nullable = true)\n",
      " |-- Western: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleanedDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ebeeb0",
   "metadata": {},
   "source": [
    "Since there are incorrectly typed columns in the schema, it must be set to the correct type first to prevent issues in the training. String columns will now be removed so only numerical columns are left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa6fc0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- vote_average: float (nullable = true)\n",
      " |-- runtime: integer (nullable = true)\n",
      " |-- popularity: float (nullable = true)\n",
      " |-- release_year: integer (nullable = true)\n",
      " |-- genre_count: integer (nullable = true)\n",
      " |-- Action: integer (nullable = true)\n",
      " |-- Adventure: integer (nullable = true)\n",
      " |-- Animation: integer (nullable = true)\n",
      " |-- comedy: integer (nullable = true)\n",
      " |-- Crime: integer (nullable = true)\n",
      " |-- Documentary: integer (nullable = true)\n",
      " |-- Drama: integer (nullable = true)\n",
      " |-- Family: integer (nullable = true)\n",
      " |-- Fantasy: integer (nullable = true)\n",
      " |-- History: integer (nullable = true)\n",
      " |-- Horror: integer (nullable = true)\n",
      " |-- Music: integer (nullable = true)\n",
      " |-- Mystery: integer (nullable = true)\n",
      " |-- Romance: integer (nullable = true)\n",
      " |-- Science Fiction: integer (nullable = true)\n",
      " |-- TV Movie: integer (nullable = true)\n",
      " |-- Thriller: integer (nullable = true)\n",
      " |-- War: integer (nullable = true)\n",
      " |-- Western: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleanedDF = cleanedDF.withColumn(\"runtime\", cleanedDF[\"runtime\"].cast(\"int\"))\n",
    "cleanedDF = cleanedDF.withColumn(\"popularity\", cleanedDF[\"popularity\"].cast(\"float\"))\n",
    "cleanedDF = cleanedDF.withColumn(\"release_year\", cleanedDF[\"release_year\"].cast(\"int\"))\n",
    "cleanedDF = cleanedDF.withColumn(\"Action\", cleanedDF[\"Action\"].cast(\"int\"))\n",
    "cleanedDF = cleanedDF.withColumn(\"Adventure\", cleanedDF[\"Adventure\"].cast(\"int\"))\n",
    "cleanedDF = cleanedDF.withColumn(\"Animation\", cleanedDF[\"Animation\"].cast(\"int\"))\n",
    "cleanedDF = cleanedDF.withColumn(\"Crime\", cleanedDF[\"Crime\"].cast(\"int\"))\n",
    "cleanedDF = cleanedDF.withColumn(\"vote_average\", cleanedDF[\"vote_average\"].cast(\"float\"))\n",
    "cleanedDF = cleanedDF.withColumn(\"genre_count\", cleanedDF[\"genre_count\"].cast(\"int\"))\n",
    "cleanedDF = cleanedDF.withColumn(\"comedy\", cleanedDF[\"comedy\"].cast(\"int\"))\n",
    "\n",
    "\n",
    "cleanedDF = cleanedDF.drop(\"title\")\n",
    "cleanedDF = cleanedDF.drop(\"status\")\n",
    "# cleanedDF = cleanedDF.drop(\"release_year\")\n",
    "# cleanedDF = cleanedDF.drop(\"popularity\")\n",
    "cleanedDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1c260e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vote_average</th>\n",
       "      <th>runtime</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release_year</th>\n",
       "      <th>genre_count</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Family</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>History</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Music</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Science Fiction</th>\n",
       "      <th>TV Movie</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.364</td>\n",
       "      <td>148.0</td>\n",
       "      <td>83.952003</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.417</td>\n",
       "      <td>169.0</td>\n",
       "      <td>140.240997</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.512</td>\n",
       "      <td>152.0</td>\n",
       "      <td>130.643005</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.573</td>\n",
       "      <td>162.0</td>\n",
       "      <td>79.931999</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.710</td>\n",
       "      <td>143.0</td>\n",
       "      <td>98.082001</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vote_average  runtime  popularity  release_year  genre_count  Action  \\\n",
       "0         8.364    148.0   83.952003        2010.0          3.0       1   \n",
       "1         8.417    169.0  140.240997        2014.0          3.0       0   \n",
       "2         8.512    152.0  130.643005        2008.0          4.0       1   \n",
       "3         7.573    162.0   79.931999        2009.0          4.0       1   \n",
       "4         7.710    143.0   98.082001        2012.0          3.0       1   \n",
       "\n",
       "   Adventure  Animation  comedy  Crime  Documentary  Drama  Family  Fantasy  \\\n",
       "0        1.0          0       0      0            0      0       0        0   \n",
       "1        1.0          0       0      0            0      1       0        0   \n",
       "2        0.0          0       0      1            0      1       0        0   \n",
       "3        1.0          0       0      0            0      0       0        1   \n",
       "4        1.0          0       0      0            0      0       0        0   \n",
       "\n",
       "   History  Horror  Music  Mystery  Romance  Science Fiction  TV Movie  \\\n",
       "0        0       0      0        0        0                1         0   \n",
       "1        0       0      0        0        0                1         0   \n",
       "2        0       0      0        0        0                0         0   \n",
       "3        0       0      0        0        0                1         0   \n",
       "4        0       0      0        0        0                1         0   \n",
       "\n",
       "   Thriller  War  Western  \n",
       "0         0    0        0  \n",
       "1         0    0        0  \n",
       "2         1    0        0  \n",
       "3         0    0        0  \n",
       "4         0    0        0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanedDF.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46e609a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cleanedPandasDF = cleanedDF.toPandas()\n",
    "# X = cleanedDF.columns[0]\n",
    "# independentColumns = cleanedDF.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2229afc4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cleanedPandasDF = cleanedPandasDF.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bbba40e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(477722, 24)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanedPandasDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4652748",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedPandasDF[\"Adventure\"] = cleanedPandasDF[\"Adventure\"].astype(float)\n",
    "X = cleanedPandasDF.drop(columns=[cleanedDF.columns[0]])\n",
    "y = cleanedPandasDF[cleanedDF.columns[0]]\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0512ae42",
   "metadata": {},
   "source": [
    "### Scaling the data\n",
    "In the EDA, the data contains outliers hence it's not applicable to use standard scaler. Robust scaler was used instead since it can handle outlier very well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6ec043b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "# scaler = StandardScaler()\n",
    "XTrainScaled = scaler.fit_transform(XTrain)\n",
    "XTestScaled = scaler.transform(XTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dbe7c9",
   "metadata": {},
   "source": [
    "### Converting to Tensorflow Dataset\n",
    "Convert the pandas dataframe to tensor dataset so that it can be used by tensforflow operations and for efficiency purposes as well (i.e. data processing and parallelism)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d441599d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-08 17:38:34.611582: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 70320568 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "# trainDataset = tf.data.Dataset.from_tensor_slices((XTrainScaled, yTrain))\n",
    "# testDataset = tf.data.Dataset.from_tensor_slices((XTestScaled, yTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18c9a9e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.fit(XTrainScaled, yTrain, epochs=100, batch_size=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c604d138",
   "metadata": {},
   "source": [
    "### Function for creating model\n",
    "It has 4 layers with 2 hidden layers since the problem is not complex. The hidden layers have 4-7 neurons (depending on the hyperparameters) which is based on the rule where each hidden layer should have a sqrt(input * output).\n",
    "\n",
    "Due to data being sparse because of one-hot encoding, Adadelta was used (which is more efficient than Adagrad). For the loss function, mean absolute error was used due to presence of outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "77a6b7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel(\n",
    "    activation = \"relu\", \n",
    "    learningRate = 0.1, \n",
    "    loss = \"mean_squared_logarithmic_error\"\n",
    "): \n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Input(shape = (XTrainScaled.shape[1],)))\n",
    "    model.add(keras.layers.Dense(\n",
    "        units = 512, \n",
    "        kernel_initializer='normal', \n",
    "        use_bias = True,\n",
    "        activation=activation))\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "    model.add(keras.layers.Dense(\n",
    "        units = 512, \n",
    "        kernel_initializer='normal', \n",
    "        use_bias = True,\n",
    "        activation=activation))\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "#     model.add(keras.layers.Dense(\n",
    "#         hiddenUnits, \n",
    "#         kernel_initializer='normal', \n",
    "#         activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(\n",
    "        1\n",
    "        ))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            learning_rate = learningRate),\n",
    "        loss=loss, \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "        \n",
    "    return model\n",
    "\n",
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Error [MPG]')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "def plot_accuracy(history):\n",
    "    plt.plot(history.history['accuracy'], label='accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy [MPG]')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f1c4d76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialModel = createModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e8b15eae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6115/6115 [==============================] - 19s 3ms/step - loss: 1.9846 - accuracy: 0.4655 - val_loss: 1.9852 - val_accuracy: 0.4655\n",
      "Epoch 2/10\n",
      "6115/6115 [==============================] - 20s 3ms/step - loss: 1.9830 - accuracy: 0.4656 - val_loss: 1.9852 - val_accuracy: 0.4655\n",
      "Epoch 3/10\n",
      "6115/6115 [==============================] - 18s 3ms/step - loss: 1.9830 - accuracy: 0.4656 - val_loss: 1.9852 - val_accuracy: 0.4655\n",
      "Epoch 4/10\n",
      "6115/6115 [==============================] - 19s 3ms/step - loss: 1.9830 - accuracy: 0.4656 - val_loss: 1.9852 - val_accuracy: 0.4655\n",
      "Epoch 5/10\n",
      "6115/6115 [==============================] - 18s 3ms/step - loss: 1.9830 - accuracy: 0.4656 - val_loss: 1.9852 - val_accuracy: 0.4655\n",
      "Epoch 6/10\n",
      "6115/6115 [==============================] - 18s 3ms/step - loss: 1.9830 - accuracy: 0.4656 - val_loss: 1.9852 - val_accuracy: 0.4655\n",
      "Epoch 7/10\n",
      "6115/6115 [==============================] - 18s 3ms/step - loss: 1.9830 - accuracy: 0.4656 - val_loss: 1.9852 - val_accuracy: 0.4655\n",
      "Epoch 8/10\n",
      "6115/6115 [==============================] - 19s 3ms/step - loss: 1.9830 - accuracy: 0.4656 - val_loss: 1.9852 - val_accuracy: 0.4655\n",
      "Epoch 9/10\n",
      "6115/6115 [==============================] - 19s 3ms/step - loss: 1.9830 - accuracy: 0.4656 - val_loss: 1.9852 - val_accuracy: 0.4655\n",
      "Epoch 10/10\n",
      "6115/6115 [==============================] - 20s 3ms/step - loss: 1.9830 - accuracy: 0.4656 - val_loss: 1.9852 - val_accuracy: 0.4655\n"
     ]
    }
   ],
   "source": [
    "history = initialModel.fit(\n",
    "    XTrainScaled,\n",
    "    yTrain,\n",
    "    validation_split = 0.2,\n",
    "    verbose = 1, epochs = 10,\n",
    "    batch_size = 50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4e50276d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cb9320ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bd5333e8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2986/2986 [==============================] - 3s 884us/step\n"
     ]
    }
   ],
   "source": [
    "initialYPred = initialModel.predict(XTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d48b0ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75147610000000.0 8668772.0 8666200.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss, mean_squared_error, mean_absolute_error\n",
    "# Calculate loss for regression\n",
    "InitialMSEloss = mean_squared_error(yTest, initialYPred)\n",
    "InitialRMSEloss = mean_squared_error(yTest, initialYPred, squared=False)\n",
    "InitialMAE = mean_absolute_error(yTest, initialYPred)\n",
    "\n",
    "print(InitialMSEloss, InitialRMSEloss, InitialMAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e5a4d8",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f50462a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = dict(\n",
    "    model__activation = [\"relu\", \"sigmoid\"],\n",
    "    batch_size = np.array([10, 50, 100]),\n",
    "    epochs = np.array([10, 20]),\n",
    "    model__learningRate = np.array([0.1, 0.01, 1]),\n",
    "    model__loss = [\"mean_squared_logarithmic_error\", \"mean_squared_error\", \"mean_absolute_error\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12d5d63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "model = KerasRegressor(build_fn=createModel,verbose=1)\n",
    "\n",
    "bestModel = RandomizedSearchCV(estimator = model,\n",
    "                               param_distributions = parameters,\n",
    "                               verbose = 1,\n",
    "                               cv = 3\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22a7c9ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Epoch 1/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 2.0688 - accuracy: 0.4645\n",
      "Epoch 2/20\n",
      "5096/5096 [==============================] - 13s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 3/20\n",
      "5096/5096 [==============================] - 13s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 4/20\n",
      "5096/5096 [==============================] - 13s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 5/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 6/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 7/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 8/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 9/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 10/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 11/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 12/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 13/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 14/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 15/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 16/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 17/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 18/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 19/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 20/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "2548/2548 [==============================] - 3s 1ms/step\n",
      "Epoch 1/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9926 - accuracy: 0.4650\n",
      "Epoch 2/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 3/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 4/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 5/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 6/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 7/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 8/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 9/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 10/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 11/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 12/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 13/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 14/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 15/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 16/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 17/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 18/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 19/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 20/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "2548/2548 [==============================] - 3s 1ms/step\n",
      "Epoch 1/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 2.1817 - accuracy: 0.4621\n",
      "Epoch 2/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 3/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 4/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 5/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 6/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 7/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 8/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 9/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 10/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 11/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 12/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 13/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 14/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 15/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 16/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 17/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 18/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 19/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 20/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "2548/2548 [==============================] - 3s 1ms/step\n",
      "Epoch 1/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9816 - accuracy: 0.4659\n",
      "Epoch 2/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 3/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 4/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 5/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 6/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 7/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 8/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 9/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 10/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 11/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 12/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 13/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 14/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 15/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 16/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 18/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 19/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 20/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "2548/2548 [==============================] - 3s 1ms/step\n",
      "Epoch 1/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9878 - accuracy: 0.4640\n",
      "Epoch 2/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 3/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 4/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 5/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 6/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 7/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 8/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 9/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 10/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 11/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 12/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 13/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 14/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 15/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 16/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 17/20\n",
      "5096/5096 [==============================] - 16s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 18/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 19/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 20/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "2548/2548 [==============================] - 3s 1ms/step\n",
      "Epoch 1/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9841 - accuracy: 0.4646\n",
      "Epoch 2/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 3/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 4/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 5/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 6/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 7/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 8/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 9/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 10/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 11/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 12/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 13/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 14/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 15/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 16/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 17/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 18/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 19/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 20/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "2548/2548 [==============================] - 3s 1ms/step\n",
      "Epoch 1/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 15.4939 - accuracy: 0.0166\n",
      "Epoch 2/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 8.1267 - accuracy: 0.0238\n",
      "Epoch 3/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 8.2367 - accuracy: 0.0229\n",
      "Epoch 4/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 8.1040 - accuracy: 0.0226\n",
      "Epoch 5/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 8.2618 - accuracy: 0.0243\n",
      "Epoch 6/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.9871 - accuracy: 0.0210\n",
      "Epoch 7/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8701 - accuracy: 0.0200\n",
      "Epoch 8/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 8.7501 - accuracy: 0.0186\n",
      "Epoch 9/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 9.1569 - accuracy: 0.0174\n",
      "Epoch 10/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8582 - accuracy: 0.0145\n",
      "Epoch 11/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8646 - accuracy: 0.0174\n",
      "Epoch 12/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8698 - accuracy: 0.0148\n",
      "Epoch 13/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 8.0394 - accuracy: 0.0140\n",
      "Epoch 14/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8519 - accuracy: 0.0146\n",
      "Epoch 15/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8329 - accuracy: 0.0153\n",
      "Epoch 16/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8344 - accuracy: 0.0151\n",
      "Epoch 17/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8535 - accuracy: 0.0155\n",
      "Epoch 18/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 8.0079 - accuracy: 0.0129\n",
      "Epoch 19/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8591 - accuracy: 0.0135\n",
      "Epoch 20/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 7.8409 - accuracy: 0.0133\n",
      "2548/2548 [==============================] - 3s 993us/step\n",
      "Epoch 1/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 10.9459 - accuracy: 0.0171\n",
      "Epoch 2/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 8.4607 - accuracy: 0.0230\n",
      "Epoch 3/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 8.4625 - accuracy: 0.0233\n",
      "Epoch 4/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.9146 - accuracy: 0.0188\n",
      "Epoch 5/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 8.0442 - accuracy: 0.0183\n",
      "Epoch 6/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.9377 - accuracy: 0.0180\n",
      "Epoch 7/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8690 - accuracy: 0.0168\n",
      "Epoch 8/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8662 - accuracy: 0.0174\n",
      "Epoch 9/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.9193 - accuracy: 0.0155\n",
      "Epoch 10/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.9225 - accuracy: 0.0146\n",
      "Epoch 11/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 8.1047 - accuracy: 0.0163\n",
      "Epoch 12/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8928 - accuracy: 0.0167\n",
      "Epoch 13/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8694 - accuracy: 0.0165\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8794 - accuracy: 0.0148\n",
      "Epoch 15/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8910 - accuracy: 0.0152\n",
      "Epoch 16/20\n",
      "5096/5096 [==============================] - 13s 3ms/step - loss: 7.9155 - accuracy: 0.0149\n",
      "Epoch 17/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8809 - accuracy: 0.0148\n",
      "Epoch 18/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8583 - accuracy: 0.0146\n",
      "Epoch 19/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8402 - accuracy: 0.0152\n",
      "Epoch 20/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8354 - accuracy: 0.0142\n",
      "2548/2548 [==============================] - 3s 978us/step\n",
      "Epoch 1/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 33.5028 - accuracy: 0.0212\n",
      "Epoch 2/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 8.3152 - accuracy: 0.0335\n",
      "Epoch 3/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 9.2633 - accuracy: 0.0310\n",
      "Epoch 4/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 8.3959 - accuracy: 0.0273\n",
      "Epoch 5/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 8.0825 - accuracy: 0.0284\n",
      "Epoch 6/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 9.2909 - accuracy: 0.0271\n",
      "Epoch 7/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.9703 - accuracy: 0.0284\n",
      "Epoch 8/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 8.2842 - accuracy: 0.0283\n",
      "Epoch 9/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 8.2682 - accuracy: 0.0235\n",
      "Epoch 10/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8999 - accuracy: 0.0227\n",
      "Epoch 11/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 7.8635 - accuracy: 0.0224\n",
      "Epoch 12/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8506 - accuracy: 0.0224\n",
      "Epoch 13/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.9062 - accuracy: 0.0219\n",
      "Epoch 14/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.9428 - accuracy: 0.0202\n",
      "Epoch 15/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8368 - accuracy: 0.0190\n",
      "Epoch 16/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8326 - accuracy: 0.0179\n",
      "Epoch 17/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 8.1779 - accuracy: 0.0198\n",
      "Epoch 18/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8266 - accuracy: 0.0197\n",
      "Epoch 19/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8320 - accuracy: 0.0186\n",
      "Epoch 20/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8544 - accuracy: 0.0187\n",
      "2548/2548 [==============================] - 3s 1ms/step\n",
      "Epoch 1/10\n",
      "25479/25479 [==============================] - 57s 2ms/step - loss: 8.6388 - accuracy: 0.0326\n",
      "Epoch 2/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 8.4616 - accuracy: 0.0376\n",
      "Epoch 3/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 8.4368 - accuracy: 0.0418\n",
      "Epoch 4/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 8.4206 - accuracy: 0.0478\n",
      "Epoch 5/10\n",
      "25479/25479 [==============================] - 54s 2ms/step - loss: 8.3895 - accuracy: 0.0494\n",
      "Epoch 6/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 8.3745 - accuracy: 0.0501\n",
      "Epoch 7/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 8.3328 - accuracy: 0.0465\n",
      "Epoch 8/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 8.3537 - accuracy: 0.0491\n",
      "Epoch 9/10\n",
      "25479/25479 [==============================] - 53s 2ms/step - loss: 8.3321 - accuracy: 0.0525\n",
      "Epoch 10/10\n",
      "25479/25479 [==============================] - 54s 2ms/step - loss: 8.3110 - accuracy: 0.0502\n",
      "12740/12740 [==============================] - 10s 812us/step\n",
      "Epoch 1/10\n",
      "25479/25479 [==============================] - 58s 2ms/step - loss: 8.7813 - accuracy: 0.0367\n",
      "Epoch 2/10\n",
      "25479/25479 [==============================] - 57s 2ms/step - loss: 8.6088 - accuracy: 0.0468\n",
      "Epoch 3/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 8.5502 - accuracy: 0.0474\n",
      "Epoch 4/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 8.4781 - accuracy: 0.0459\n",
      "Epoch 5/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 8.4808 - accuracy: 0.0512\n",
      "Epoch 6/10\n",
      "25479/25479 [==============================] - 57s 2ms/step - loss: 8.4341 - accuracy: 0.0524\n",
      "Epoch 7/10\n",
      "25479/25479 [==============================] - 61s 2ms/step - loss: 8.4361 - accuracy: 0.0508\n",
      "Epoch 8/10\n",
      "25479/25479 [==============================] - 57s 2ms/step - loss: 8.4078 - accuracy: 0.0536\n",
      "Epoch 9/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 8.4185 - accuracy: 0.0542\n",
      "Epoch 10/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 8.3981 - accuracy: 0.0537\n",
      "12740/12740 [==============================] - 10s 798us/step\n",
      "Epoch 1/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 8.7296 - accuracy: 0.0349\n",
      "Epoch 2/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 8.5634 - accuracy: 0.0451\n",
      "Epoch 3/10\n",
      "25479/25479 [==============================] - 57s 2ms/step - loss: 8.4989 - accuracy: 0.0467\n",
      "Epoch 4/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 8.4328 - accuracy: 0.0467\n",
      "Epoch 5/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 8.4224 - accuracy: 0.0489\n",
      "Epoch 6/10\n",
      "25479/25479 [==============================] - 57s 2ms/step - loss: 8.4157 - accuracy: 0.0502\n",
      "Epoch 7/10\n",
      "25479/25479 [==============================] - 59s 2ms/step - loss: 8.3996 - accuracy: 0.0507\n",
      "Epoch 8/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 8.3776 - accuracy: 0.0514\n",
      "Epoch 9/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 8.3927 - accuracy: 0.0533\n",
      "Epoch 10/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 8.3784 - accuracy: 0.0538\n",
      "12740/12740 [==============================] - 10s 796us/step\n",
      "Epoch 1/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 48.3800 - accuracy: 0.0200\n",
      "Epoch 2/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 3.0898 - accuracy: 0.0198\n",
      "Epoch 3/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 3.0810 - accuracy: 0.0211\n",
      "Epoch 4/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 3.0791 - accuracy: 0.0203\n",
      "Epoch 5/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 3.0810 - accuracy: 0.0191\n",
      "Epoch 6/10\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 3.0780 - accuracy: 0.0225\n",
      "Epoch 7/10\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 3.0843 - accuracy: 0.0207\n",
      "Epoch 8/10\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 3.0835 - accuracy: 0.0188\n",
      "Epoch 9/10\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 3.0828 - accuracy: 0.0209\n",
      "Epoch 10/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 3.0998 - accuracy: 0.0158\n",
      "2548/2548 [==============================] - 3s 1ms/step\n",
      "Epoch 1/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 50.0403 - accuracy: 0.0223\n",
      "Epoch 2/10\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 3.0835 - accuracy: 0.0203\n",
      "Epoch 3/10\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 3.0867 - accuracy: 0.0171\n",
      "Epoch 4/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 3.0839 - accuracy: 0.0171\n",
      "Epoch 5/10\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 3.0858 - accuracy: 0.0200\n",
      "Epoch 6/10\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 3.0862 - accuracy: 0.0178\n",
      "Epoch 7/10\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 3.1603 - accuracy: 0.0169\n",
      "Epoch 8/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 3.0832 - accuracy: 0.0203\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5096/5096 [==============================] - 14s 3ms/step - loss: 3.0856 - accuracy: 0.0184\n",
      "Epoch 10/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 3.0832 - accuracy: 0.0188\n",
      "2548/2548 [==============================] - 3s 1ms/step\n",
      "Epoch 1/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 100.6689 - accuracy: 0.0204\n",
      "Epoch 2/10\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 3.3943 - accuracy: 0.0176\n",
      "Epoch 3/10\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 3.0820 - accuracy: 0.0228\n",
      "Epoch 4/10\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 3.0808 - accuracy: 0.0234\n",
      "Epoch 5/10\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 3.0839 - accuracy: 0.0215\n",
      "Epoch 6/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 3.0777 - accuracy: 0.0199\n",
      "Epoch 7/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 3.0805 - accuracy: 0.0203\n",
      "Epoch 8/10\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 3.1081 - accuracy: 0.0191\n",
      "Epoch 9/10\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 3.0804 - accuracy: 0.0208\n",
      "Epoch 10/10\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 3.0818 - accuracy: 0.0169\n",
      "2548/2548 [==============================] - 3s 981us/step\n",
      "Epoch 1/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 2.0328 - accuracy: 0.3234\n",
      "Epoch 2/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.9446 - accuracy: 0.3557\n",
      "Epoch 3/20\n",
      "2548/2548 [==============================] - 8s 3ms/step - loss: 1.9161 - accuracy: 0.3486\n",
      "Epoch 4/20\n",
      "2548/2548 [==============================] - 9s 4ms/step - loss: 1.8933 - accuracy: 0.3472\n",
      "Epoch 5/20\n",
      "2548/2548 [==============================] - 9s 4ms/step - loss: 1.8792 - accuracy: 0.3523\n",
      "Epoch 6/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8655 - accuracy: 0.3530\n",
      "Epoch 7/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8550 - accuracy: 0.3529\n",
      "Epoch 8/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8466 - accuracy: 0.3529\n",
      "Epoch 9/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8353 - accuracy: 0.3546\n",
      "Epoch 10/20\n",
      "2548/2548 [==============================] - 8s 3ms/step - loss: 1.8278 - accuracy: 0.3556\n",
      "Epoch 11/20\n",
      "2548/2548 [==============================] - 8s 3ms/step - loss: 1.8237 - accuracy: 0.3571\n",
      "Epoch 12/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8189 - accuracy: 0.3570\n",
      "Epoch 13/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8182 - accuracy: 0.3573\n",
      "Epoch 14/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8138 - accuracy: 0.3573\n",
      "Epoch 15/20\n",
      "2548/2548 [==============================] - 8s 3ms/step - loss: 1.8096 - accuracy: 0.3576\n",
      "Epoch 16/20\n",
      "2548/2548 [==============================] - 9s 4ms/step - loss: 1.8062 - accuracy: 0.3584\n",
      "Epoch 17/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8043 - accuracy: 0.3595\n",
      "Epoch 18/20\n",
      "2548/2548 [==============================] - 8s 3ms/step - loss: 1.8008 - accuracy: 0.3585\n",
      "Epoch 19/20\n",
      "2548/2548 [==============================] - 8s 3ms/step - loss: 1.8030 - accuracy: 0.3594\n",
      "Epoch 20/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.7994 - accuracy: 0.3595\n",
      "1274/1274 [==============================] - 2s 1ms/step\n",
      "Epoch 1/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 2.0474 - accuracy: 0.3148\n",
      "Epoch 2/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.9271 - accuracy: 0.3457\n",
      "Epoch 3/20\n",
      "2548/2548 [==============================] - 9s 4ms/step - loss: 1.9140 - accuracy: 0.3455\n",
      "Epoch 4/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.9031 - accuracy: 0.3450\n",
      "Epoch 5/20\n",
      "2548/2548 [==============================] - 8s 3ms/step - loss: 1.8969 - accuracy: 0.3447\n",
      "Epoch 6/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8884 - accuracy: 0.3431\n",
      "Epoch 7/20\n",
      "2548/2548 [==============================] - 9s 4ms/step - loss: 1.8785 - accuracy: 0.3431\n",
      "Epoch 8/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8659 - accuracy: 0.3493\n",
      "Epoch 9/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8571 - accuracy: 0.3521\n",
      "Epoch 10/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8525 - accuracy: 0.3524\n",
      "Epoch 11/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8453 - accuracy: 0.3539\n",
      "Epoch 12/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8400 - accuracy: 0.3542\n",
      "Epoch 13/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8366 - accuracy: 0.3549\n",
      "Epoch 14/20\n",
      "2548/2548 [==============================] - 9s 4ms/step - loss: 1.8327 - accuracy: 0.3552\n",
      "Epoch 15/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8292 - accuracy: 0.3558\n",
      "Epoch 16/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8290 - accuracy: 0.3555\n",
      "Epoch 17/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8231 - accuracy: 0.3574\n",
      "Epoch 18/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8200 - accuracy: 0.3566\n",
      "Epoch 19/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8195 - accuracy: 0.3566\n",
      "Epoch 20/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8176 - accuracy: 0.3581\n",
      "1274/1274 [==============================] - 2s 1ms/step\n",
      "Epoch 1/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 2.0476 - accuracy: 0.3154\n",
      "Epoch 2/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.9336 - accuracy: 0.3559\n",
      "Epoch 3/20\n",
      "2548/2548 [==============================] - 8s 3ms/step - loss: 1.9111 - accuracy: 0.3509\n",
      "Epoch 4/20\n",
      "2548/2548 [==============================] - 8s 3ms/step - loss: 1.8921 - accuracy: 0.3529\n",
      "Epoch 5/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8798 - accuracy: 0.3550\n",
      "Epoch 6/20\n",
      "2548/2548 [==============================] - 8s 3ms/step - loss: 1.8701 - accuracy: 0.3557\n",
      "Epoch 7/20\n",
      "2548/2548 [==============================] - 8s 3ms/step - loss: 1.8578 - accuracy: 0.3566\n",
      "Epoch 8/20\n",
      "2548/2548 [==============================] - 8s 3ms/step - loss: 1.8501 - accuracy: 0.3568\n",
      "Epoch 9/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8442 - accuracy: 0.3578\n",
      "Epoch 10/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8366 - accuracy: 0.3589\n",
      "Epoch 11/20\n",
      "2548/2548 [==============================] - 8s 3ms/step - loss: 1.8311 - accuracy: 0.3586\n",
      "Epoch 12/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8261 - accuracy: 0.3594\n",
      "Epoch 13/20\n",
      "2548/2548 [==============================] - 8s 3ms/step - loss: 1.8230 - accuracy: 0.3608\n",
      "Epoch 14/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8209 - accuracy: 0.3610\n",
      "Epoch 15/20\n",
      "2548/2548 [==============================] - 8s 3ms/step - loss: 1.8162 - accuracy: 0.3617\n",
      "Epoch 16/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8156 - accuracy: 0.3602\n",
      "Epoch 17/20\n",
      "2548/2548 [==============================] - 8s 3ms/step - loss: 1.8116 - accuracy: 0.3615\n",
      "Epoch 18/20\n",
      "2548/2548 [==============================] - 8s 3ms/step - loss: 1.8105 - accuracy: 0.3622\n",
      "Epoch 19/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8107 - accuracy: 0.3618\n",
      "Epoch 20/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8076 - accuracy: 0.3624\n",
      "1274/1274 [==============================] - 2s 1ms/step\n",
      "Epoch 1/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 2.0214 - accuracy: 0.3294\n",
      "Epoch 2/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9446 - accuracy: 0.3472\n",
      "Epoch 3/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9189 - accuracy: 0.3437\n",
      "Epoch 4/10\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9027 - accuracy: 0.3445\n",
      "Epoch 5/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.8877 - accuracy: 0.3465\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.8726 - accuracy: 0.3506\n",
      "Epoch 7/10\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.8670 - accuracy: 0.3498\n",
      "Epoch 8/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.8582 - accuracy: 0.3497\n",
      "Epoch 9/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.8526 - accuracy: 0.3504\n",
      "Epoch 10/10\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.8433 - accuracy: 0.3524\n",
      "2548/2548 [==============================] - 3s 1ms/step\n",
      "Epoch 1/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 2.0194 - accuracy: 0.3190\n",
      "Epoch 2/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9355 - accuracy: 0.3416\n",
      "Epoch 3/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9226 - accuracy: 0.3419\n",
      "Epoch 4/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9104 - accuracy: 0.3412\n",
      "Epoch 5/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.8984 - accuracy: 0.3455\n",
      "Epoch 6/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.8900 - accuracy: 0.3465\n",
      "Epoch 7/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.8847 - accuracy: 0.3467\n",
      "Epoch 8/10\n",
      "5096/5096 [==============================] - 16s 3ms/step - loss: 1.8774 - accuracy: 0.3486\n",
      "Epoch 9/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.8677 - accuracy: 0.3498\n",
      "Epoch 10/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.8589 - accuracy: 0.3515\n",
      "2548/2548 [==============================] - 3s 1ms/step\n",
      "Epoch 1/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 2.0330 - accuracy: 0.3172\n",
      "Epoch 2/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9457 - accuracy: 0.3420\n",
      "Epoch 3/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9219 - accuracy: 0.3434\n",
      "Epoch 4/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9057 - accuracy: 0.3439\n",
      "Epoch 5/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.8940 - accuracy: 0.3453\n",
      "Epoch 6/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.8776 - accuracy: 0.3490\n",
      "Epoch 7/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.8652 - accuracy: 0.3510\n",
      "Epoch 8/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.8610 - accuracy: 0.3516\n",
      "Epoch 9/10\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.8555 - accuracy: 0.3525\n",
      "Epoch 10/10\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.8496 - accuracy: 0.3534\n",
      "2548/2548 [==============================] - 3s 1ms/step\n",
      "Epoch 1/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 20.1427 - accuracy: 0.0955\n",
      "Epoch 2/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 19.6417 - accuracy: 0.0923\n",
      "Epoch 3/10\n",
      "25479/25479 [==============================] - 58s 2ms/step - loss: 19.8984 - accuracy: 0.0919\n",
      "Epoch 4/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 19.8353 - accuracy: 0.0940\n",
      "Epoch 5/10\n",
      "25479/25479 [==============================] - 57s 2ms/step - loss: 20.0467 - accuracy: 0.0958\n",
      "Epoch 6/10\n",
      "25479/25479 [==============================] - 54s 2ms/step - loss: 20.1517 - accuracy: 0.0962\n",
      "Epoch 7/10\n",
      "25479/25479 [==============================] - 54s 2ms/step - loss: 19.8425 - accuracy: 0.0934\n",
      "Epoch 8/10\n",
      "25479/25479 [==============================] - 54s 2ms/step - loss: 20.1423 - accuracy: 0.0955\n",
      "Epoch 9/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 20.0052 - accuracy: 0.0946\n",
      "Epoch 10/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 20.1829 - accuracy: 0.0963\n",
      "12740/12740 [==============================] - 10s 777us/step\n",
      "Epoch 1/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 19.5303 - accuracy: 0.0916\n",
      "Epoch 2/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 19.4230 - accuracy: 0.0912\n",
      "Epoch 3/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 19.5654 - accuracy: 0.0921\n",
      "Epoch 4/10\n",
      "25479/25479 [==============================] - 54s 2ms/step - loss: 19.6711 - accuracy: 0.0938\n",
      "Epoch 5/10\n",
      "25479/25479 [==============================] - 54s 2ms/step - loss: 19.4072 - accuracy: 0.0912\n",
      "Epoch 6/10\n",
      "25479/25479 [==============================] - 54s 2ms/step - loss: 19.4127 - accuracy: 0.0912\n",
      "Epoch 7/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 19.6572 - accuracy: 0.0919\n",
      "Epoch 8/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 19.7760 - accuracy: 0.0931\n",
      "Epoch 9/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 19.4797 - accuracy: 0.0913\n",
      "Epoch 10/10\n",
      "25479/25479 [==============================] - 54s 2ms/step - loss: 19.5509 - accuracy: 0.0929\n",
      "12740/12740 [==============================] - 10s 817us/step\n",
      "Epoch 1/10\n",
      "25479/25479 [==============================] - 58s 2ms/step - loss: 20.0688 - accuracy: 0.0947\n",
      "Epoch 2/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 19.8499 - accuracy: 0.0939\n",
      "Epoch 3/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 19.5897 - accuracy: 0.0930\n",
      "Epoch 4/10\n",
      "25479/25479 [==============================] - 54s 2ms/step - loss: 19.7860 - accuracy: 0.0933\n",
      "Epoch 5/10\n",
      "25479/25479 [==============================] - 54s 2ms/step - loss: 19.7044 - accuracy: 0.0936\n",
      "Epoch 6/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 19.8758 - accuracy: 0.0940\n",
      "Epoch 7/10\n",
      "25479/25479 [==============================] - 54s 2ms/step - loss: 19.7558 - accuracy: 0.0937\n",
      "Epoch 8/10\n",
      "25479/25479 [==============================] - 54s 2ms/step - loss: 19.8261 - accuracy: 0.0945\n",
      "Epoch 9/10\n",
      "25479/25479 [==============================] - 54s 2ms/step - loss: 19.7341 - accuracy: 0.0923\n",
      "Epoch 10/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 19.8832 - accuracy: 0.0941\n",
      "12740/12740 [==============================] - 10s 819us/step\n",
      "Epoch 1/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 225.8432 - accuracy: 0.1960\n",
      "Epoch 2/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 222.3070 - accuracy: 0.1999\n",
      "Epoch 3/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 227.2739 - accuracy: 0.1986\n",
      "Epoch 4/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 224.9395 - accuracy: 0.1996\n",
      "Epoch 5/10\n",
      "25479/25479 [==============================] - 57s 2ms/step - loss: 223.2708 - accuracy: 0.2002\n",
      "Epoch 6/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 222.2059 - accuracy: 0.1996\n",
      "Epoch 7/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 226.1048 - accuracy: 0.1985\n",
      "Epoch 8/10\n",
      "25479/25479 [==============================] - 57s 2ms/step - loss: 225.3945 - accuracy: 0.1996\n",
      "Epoch 9/10\n",
      "25479/25479 [==============================] - 57s 2ms/step - loss: 217.5882 - accuracy: 0.1989\n",
      "Epoch 10/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 224.6839 - accuracy: 0.1992\n",
      "12740/12740 [==============================] - 10s 801us/step\n",
      "Epoch 1/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 188.0739 - accuracy: 0.1954\n",
      "Epoch 2/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 193.3909 - accuracy: 0.1958\n",
      "Epoch 3/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 189.4657 - accuracy: 0.1965\n",
      "Epoch 4/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 187.9893 - accuracy: 0.1959\n",
      "Epoch 5/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 189.5925 - accuracy: 0.1955\n",
      "Epoch 6/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 194.3233 - accuracy: 0.1956\n",
      "Epoch 7/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 192.3532 - accuracy: 0.1972\n",
      "Epoch 8/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 188.8991 - accuracy: 0.1962\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25479/25479 [==============================] - 55s 2ms/step - loss: 188.8671 - accuracy: 0.1966\n",
      "Epoch 10/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 185.9577 - accuracy: 0.1982\n",
      "12740/12740 [==============================] - 10s 793us/step\n",
      "Epoch 1/10\n",
      "25479/25479 [==============================] - 54s 2ms/step - loss: 212.4160 - accuracy: 0.1935\n",
      "Epoch 2/10\n",
      "25479/25479 [==============================] - 54s 2ms/step - loss: 203.2683 - accuracy: 0.1971\n",
      "Epoch 3/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 202.8325 - accuracy: 0.1993\n",
      "Epoch 4/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 203.6101 - accuracy: 0.1986\n",
      "Epoch 5/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 202.8246 - accuracy: 0.1976\n",
      "Epoch 6/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 201.4494 - accuracy: 0.1986\n",
      "Epoch 7/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 205.3990 - accuracy: 0.1986\n",
      "Epoch 8/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 200.4589 - accuracy: 0.1974\n",
      "Epoch 9/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 207.6128 - accuracy: 0.1979\n",
      "Epoch 10/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 200.1082 - accuracy: 0.1984\n",
      "12740/12740 [==============================] - 10s 799us/step\n",
      "Epoch 1/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 2.0015 - accuracy: 0.4660\n",
      "Epoch 2/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 3/20\n",
      "5096/5096 [==============================] - 16s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 4/20\n",
      "5096/5096 [==============================] - 16s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 5/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 6/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 7/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 8/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 9/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 10/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 11/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 12/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 13/20\n",
      "5096/5096 [==============================] - 16s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 14/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 15/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 16/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 17/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 18/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 19/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 20/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "2548/2548 [==============================] - 3s 1ms/step\n",
      "Epoch 1/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 2.0108 - accuracy: 0.4650\n",
      "Epoch 2/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 3/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 4/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 5/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 6/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 7/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 8/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 9/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 10/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 11/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 12/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 13/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 14/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 15/20\n",
      "5096/5096 [==============================] - 16s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 16/20\n",
      "5096/5096 [==============================] - 16s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 17/20\n",
      "5096/5096 [==============================] - 21s 4ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 18/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 19/20\n",
      "5096/5096 [==============================] - 33s 6ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 20/20\n",
      "5096/5096 [==============================] - 36s 7ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "2548/2548 [==============================] - 3s 1ms/step\n",
      "Epoch 1/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 2.0176 - accuracy: 0.4652\n",
      "Epoch 2/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 3/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 4/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 5/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 6/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 7/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 8/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 9/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 10/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 11/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 12/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 13/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 14/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 15/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 16/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 17/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 18/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 19/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 20/20\n",
      "5096/5096 [==============================] - 17s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "2548/2548 [==============================] - 3s 1ms/step\n",
      "Epoch 1/20\n",
      "7644/7644 [==============================] - 23s 3ms/step - loss: 19.0632 - accuracy: 0.0248\n",
      "Epoch 2/20\n",
      "7644/7644 [==============================] - 23s 3ms/step - loss: 9.3461 - accuracy: 0.0341\n",
      "Epoch 3/20\n",
      "7644/7644 [==============================] - 23s 3ms/step - loss: 8.0525 - accuracy: 0.0296\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7644/7644 [==============================] - 22s 3ms/step - loss: 7.9720 - accuracy: 0.0275\n",
      "Epoch 5/20\n",
      "7644/7644 [==============================] - 22s 3ms/step - loss: 8.0521 - accuracy: 0.0272\n",
      "Epoch 6/20\n",
      "7644/7644 [==============================] - 21s 3ms/step - loss: 9.3620 - accuracy: 0.0283\n",
      "Epoch 7/20\n",
      "7644/7644 [==============================] - 22s 3ms/step - loss: 8.0196 - accuracy: 0.0277\n",
      "Epoch 8/20\n",
      "7644/7644 [==============================] - 28s 4ms/step - loss: 8.0815 - accuracy: 0.0266\n",
      "Epoch 9/20\n",
      "7644/7644 [==============================] - 27s 3ms/step - loss: 7.9630 - accuracy: 0.0240\n",
      "Epoch 10/20\n",
      "7644/7644 [==============================] - 27s 3ms/step - loss: 8.2933 - accuracy: 0.0240\n",
      "Epoch 11/20\n",
      "7644/7644 [==============================] - 22s 3ms/step - loss: 9.3947 - accuracy: 0.0215\n",
      "Epoch 12/20\n",
      "7644/7644 [==============================] - 21s 3ms/step - loss: 8.0745 - accuracy: 0.0168\n",
      "Epoch 13/20\n",
      "7644/7644 [==============================] - 21s 3ms/step - loss: 7.8858 - accuracy: 0.0188\n",
      "Epoch 14/20\n",
      "7644/7644 [==============================] - 22s 3ms/step - loss: 7.8937 - accuracy: 0.0200\n",
      "Epoch 15/20\n",
      "7644/7644 [==============================] - 25s 3ms/step - loss: 7.8855 - accuracy: 0.0205\n",
      "Epoch 16/20\n",
      "7644/7644 [==============================] - 21s 3ms/step - loss: 7.8816 - accuracy: 0.0193\n",
      "Epoch 17/20\n",
      "7644/7644 [==============================] - 21s 3ms/step - loss: 7.8601 - accuracy: 0.0199\n",
      "Epoch 18/20\n",
      "7644/7644 [==============================] - 21s 3ms/step - loss: 7.9261 - accuracy: 0.0160\n",
      "Epoch 19/20\n",
      "7644/7644 [==============================] - 21s 3ms/step - loss: 7.9164 - accuracy: 0.0153\n",
      "Epoch 20/20\n",
      "7644/7644 [==============================] - 22s 3ms/step - loss: 10.4195 - accuracy: 0.0162\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=KerasRegressor(build_fn=&lt;function createModel at 0x7f65d444cee0&gt;),\n",
       "                   param_distributions={&#x27;batch_size&#x27;: array([ 10,  50, 100]),\n",
       "                                        &#x27;epochs&#x27;: array([10, 20]),\n",
       "                                        &#x27;model__activation&#x27;: [&#x27;relu&#x27;,\n",
       "                                                              &#x27;sigmoid&#x27;],\n",
       "                                        &#x27;model__learningRate&#x27;: array([0.1 , 0.01, 1.  ]),\n",
       "                                        &#x27;model__loss&#x27;: [&#x27;mean_squared_logarithmic_error&#x27;,\n",
       "                                                        &#x27;mean_squared_error&#x27;,\n",
       "                                                        &#x27;mean_absolute_error&#x27;]},\n",
       "                   verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=KerasRegressor(build_fn=&lt;function createModel at 0x7f65d444cee0&gt;),\n",
       "                   param_distributions={&#x27;batch_size&#x27;: array([ 10,  50, 100]),\n",
       "                                        &#x27;epochs&#x27;: array([10, 20]),\n",
       "                                        &#x27;model__activation&#x27;: [&#x27;relu&#x27;,\n",
       "                                                              &#x27;sigmoid&#x27;],\n",
       "                                        &#x27;model__learningRate&#x27;: array([0.1 , 0.01, 1.  ]),\n",
       "                                        &#x27;model__loss&#x27;: [&#x27;mean_squared_logarithmic_error&#x27;,\n",
       "                                                        &#x27;mean_squared_error&#x27;,\n",
       "                                                        &#x27;mean_absolute_error&#x27;]},\n",
       "                   verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>KerasRegressor(\n",
       "\tmodel=None\n",
       "\tbuild_fn=&lt;function createModel at 0x7f65d444cee0&gt;\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=1\n",
       ")</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>KerasRegressor(\n",
       "\tmodel=None\n",
       "\tbuild_fn=&lt;function createModel at 0x7f65d444cee0&gt;\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=1\n",
       ")</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=KerasRegressor(build_fn=<function createModel at 0x7f65d444cee0>),\n",
       "                   param_distributions={'batch_size': array([ 10,  50, 100]),\n",
       "                                        'epochs': array([10, 20]),\n",
       "                                        'model__activation': ['relu',\n",
       "                                                              'sigmoid'],\n",
       "                                        'model__learningRate': array([0.1 , 0.01, 1.  ]),\n",
       "                                        'model__loss': ['mean_squared_logarithmic_error',\n",
       "                                                        'mean_squared_error',\n",
       "                                                        'mean_absolute_error']},\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestModel.fit(XTrainScaled, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f11b2434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KerasRegressor(\n",
       "\tmodel=None\n",
       "\tbuild_fn=&lt;function createModel at 0x7f65d444cee0&gt;\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=50\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=20\n",
       "\tmodel__loss=mean_squared_error\n",
       "\tmodel__learningRate=0.01\n",
       "\tmodel__activation=relu\n",
       ")</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>KerasRegressor(\n",
       "\tmodel=None\n",
       "\tbuild_fn=&lt;function createModel at 0x7f65d444cee0&gt;\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=50\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=20\n",
       "\tmodel__loss=mean_squared_error\n",
       "\tmodel__learningRate=0.01\n",
       "\tmodel__activation=relu\n",
       ")</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KerasRegressor(\n",
       "\tmodel=None\n",
       "\tbuild_fn=<function createModel at 0x7f65d444cee0>\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=50\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=20\n",
       "\tmodel__loss=mean_squared_error\n",
       "\tmodel__learningRate=0.01\n",
       "\tmodel__activation=relu\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tunedNN = bestModel.best_estimator_\n",
    "tunedNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0bcf242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2750273936908877"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestModel.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c6340212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([297.17978605, 286.88663371, 292.3755451 , 559.64894772,\n",
       "        144.68660466, 173.09685755, 148.63535778, 554.12388714,\n",
       "        556.3929321 , 323.5685273 ]),\n",
       " 'std_fit_time': array([18.3143848 ,  2.23915228, 21.2446483 ,  7.13677238,  0.77415385,\n",
       "         1.05312969,  1.66271529,  6.24163712,  3.90453743, 41.55548141]),\n",
       " 'mean_score_time': array([ 3.1051542 ,  2.95088784,  2.85012587, 14.74872017,  3.62145011,\n",
       "         1.89247719,  3.79672662, 11.45707583, 14.40437404,  3.72881969]),\n",
       " 'std_score_time': array([0.09268735, 0.08853294, 0.04719489, 4.118017  , 1.09672168,\n",
       "        0.03200071, 0.97643142, 0.22272141, 4.3348484 , 1.02421738]),\n",
       " 'param_model__loss': masked_array(data=['mean_squared_logarithmic_error',\n",
       "                    'mean_squared_logarithmic_error', 'mean_squared_error',\n",
       "                    'mean_squared_error', 'mean_absolute_error',\n",
       "                    'mean_absolute_error', 'mean_absolute_error',\n",
       "                    'mean_squared_error', 'mean_squared_error',\n",
       "                    'mean_squared_logarithmic_error'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_model__learningRate': masked_array(data=[1.0, 0.01, 0.01, 0.01, 1.0, 0.01, 0.01, 0.1, 1.0, 1.0],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_model__activation': masked_array(data=['sigmoid', 'sigmoid', 'relu', 'sigmoid', 'relu',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'relu'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_epochs': masked_array(data=[20, 20, 20, 10, 10, 20, 10, 10, 10, 20],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_batch_size': masked_array(data=[50, 50, 50, 10, 50, 100, 50, 10, 10, 50],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'model__loss': 'mean_squared_logarithmic_error',\n",
       "   'model__learningRate': 1.0,\n",
       "   'model__activation': 'sigmoid',\n",
       "   'epochs': 20,\n",
       "   'batch_size': 50},\n",
       "  {'model__loss': 'mean_squared_logarithmic_error',\n",
       "   'model__learningRate': 0.01,\n",
       "   'model__activation': 'sigmoid',\n",
       "   'epochs': 20,\n",
       "   'batch_size': 50},\n",
       "  {'model__loss': 'mean_squared_error',\n",
       "   'model__learningRate': 0.01,\n",
       "   'model__activation': 'relu',\n",
       "   'epochs': 20,\n",
       "   'batch_size': 50},\n",
       "  {'model__loss': 'mean_squared_error',\n",
       "   'model__learningRate': 0.01,\n",
       "   'model__activation': 'sigmoid',\n",
       "   'epochs': 10,\n",
       "   'batch_size': 10},\n",
       "  {'model__loss': 'mean_absolute_error',\n",
       "   'model__learningRate': 1.0,\n",
       "   'model__activation': 'relu',\n",
       "   'epochs': 10,\n",
       "   'batch_size': 50},\n",
       "  {'model__loss': 'mean_absolute_error',\n",
       "   'model__learningRate': 0.01,\n",
       "   'model__activation': 'sigmoid',\n",
       "   'epochs': 20,\n",
       "   'batch_size': 100},\n",
       "  {'model__loss': 'mean_absolute_error',\n",
       "   'model__learningRate': 0.01,\n",
       "   'model__activation': 'sigmoid',\n",
       "   'epochs': 10,\n",
       "   'batch_size': 50},\n",
       "  {'model__loss': 'mean_squared_error',\n",
       "   'model__learningRate': 0.1,\n",
       "   'model__activation': 'sigmoid',\n",
       "   'epochs': 10,\n",
       "   'batch_size': 10},\n",
       "  {'model__loss': 'mean_squared_error',\n",
       "   'model__learningRate': 1.0,\n",
       "   'model__activation': 'sigmoid',\n",
       "   'epochs': 10,\n",
       "   'batch_size': 10},\n",
       "  {'model__loss': 'mean_squared_logarithmic_error',\n",
       "   'model__learningRate': 1.0,\n",
       "   'model__activation': 'relu',\n",
       "   'epochs': 20,\n",
       "   'batch_size': 50}],\n",
       " 'split0_test_score': array([-2.16039097e+05, -4.94313539e+00,  2.68070910e-01,  2.69007238e-01,\n",
       "        -2.31801470e-02,  1.36862602e-01,  1.42317990e-01, -2.03542345e+00,\n",
       "        -2.88292361e+00, -2.44943682e+13]),\n",
       " 'split1_test_score': array([-2.20784198e+05, -8.52516224e+00,  2.77267430e-01,  1.72689541e-01,\n",
       "        -6.93384875e-02,  1.49230255e-01,  1.51623486e-01, -1.18474033e+00,\n",
       "        -4.29038471e+01, -7.50073686e+13]),\n",
       " 'split2_test_score': array([-1.38144647e+05, -3.23637078e+00,  2.79743841e-01, -3.97974231e-02,\n",
       "        -2.02183671e-01,  1.42660488e-01,  1.23016163e-01, -1.05025103e-01,\n",
       "        -1.06771917e+01, -2.86496189e+12]),\n",
       " 'mean_test_score': array([-1.91655981e+05, -5.56822281e+00,  2.75027394e-01,  1.33966452e-01,\n",
       "        -9.82341017e-02,  1.42917782e-01,  1.38985880e-01, -1.10839630e+00,\n",
       "        -1.88213208e+01, -3.41222329e+13]),\n",
       " 'std_test_score': array([3.78877827e+04, 2.20391765e+00, 5.02179578e-03, 1.29008237e-01,\n",
       "        7.58805322e-02, 5.05234990e-03, 1.19141921e-02, 7.89928586e-01,\n",
       "        1.73236584e+01, 3.02286128e+13]),\n",
       " 'rank_test_score': array([ 9,  7,  1,  4,  5,  2,  3,  6,  8, 10], dtype=int32)}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestModel.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1663f35d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__loss': 'mean_squared_error',\n",
       " 'model__learningRate': 0.01,\n",
       " 'model__activation': 'relu',\n",
       " 'epochs': 20,\n",
       " 'batch_size': 50}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestModel.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e6b2c82a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_model__loss</th>\n",
       "      <th>param_model__learningRate</th>\n",
       "      <th>param_model__activation</th>\n",
       "      <th>param_epochs</th>\n",
       "      <th>param_batch_size</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>297.179786</td>\n",
       "      <td>18.314385</td>\n",
       "      <td>3.105154</td>\n",
       "      <td>0.092687</td>\n",
       "      <td>mean_squared_logarithmic_error</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>{'model__loss': 'mean_squared_logarithmic_erro...</td>\n",
       "      <td>-2.160391e+05</td>\n",
       "      <td>-2.207842e+05</td>\n",
       "      <td>-1.381446e+05</td>\n",
       "      <td>-1.916560e+05</td>\n",
       "      <td>3.788778e+04</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>286.886634</td>\n",
       "      <td>2.239152</td>\n",
       "      <td>2.950888</td>\n",
       "      <td>0.088533</td>\n",
       "      <td>mean_squared_logarithmic_error</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>{'model__loss': 'mean_squared_logarithmic_erro...</td>\n",
       "      <td>-4.943135e+00</td>\n",
       "      <td>-8.525162e+00</td>\n",
       "      <td>-3.236371e+00</td>\n",
       "      <td>-5.568223e+00</td>\n",
       "      <td>2.203918e+00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>292.375545</td>\n",
       "      <td>21.244648</td>\n",
       "      <td>2.850126</td>\n",
       "      <td>0.047195</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>0.01</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>{'model__loss': 'mean_squared_error', 'model__...</td>\n",
       "      <td>2.680709e-01</td>\n",
       "      <td>2.772674e-01</td>\n",
       "      <td>2.797438e-01</td>\n",
       "      <td>2.750274e-01</td>\n",
       "      <td>5.021796e-03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>559.648948</td>\n",
       "      <td>7.136772</td>\n",
       "      <td>14.748720</td>\n",
       "      <td>4.118017</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'model__loss': 'mean_squared_error', 'model__...</td>\n",
       "      <td>2.690072e-01</td>\n",
       "      <td>1.726895e-01</td>\n",
       "      <td>-3.979742e-02</td>\n",
       "      <td>1.339665e-01</td>\n",
       "      <td>1.290082e-01</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>144.686605</td>\n",
       "      <td>0.774154</td>\n",
       "      <td>3.621450</td>\n",
       "      <td>1.096722</td>\n",
       "      <td>mean_absolute_error</td>\n",
       "      <td>1.0</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'model__loss': 'mean_absolute_error', 'model_...</td>\n",
       "      <td>-2.318015e-02</td>\n",
       "      <td>-6.933849e-02</td>\n",
       "      <td>-2.021837e-01</td>\n",
       "      <td>-9.823410e-02</td>\n",
       "      <td>7.588053e-02</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>173.096858</td>\n",
       "      <td>1.053130</td>\n",
       "      <td>1.892477</td>\n",
       "      <td>0.032001</td>\n",
       "      <td>mean_absolute_error</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>{'model__loss': 'mean_absolute_error', 'model_...</td>\n",
       "      <td>1.368626e-01</td>\n",
       "      <td>1.492303e-01</td>\n",
       "      <td>1.426605e-01</td>\n",
       "      <td>1.429178e-01</td>\n",
       "      <td>5.052350e-03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>148.635358</td>\n",
       "      <td>1.662715</td>\n",
       "      <td>3.796727</td>\n",
       "      <td>0.976431</td>\n",
       "      <td>mean_absolute_error</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'model__loss': 'mean_absolute_error', 'model_...</td>\n",
       "      <td>1.423180e-01</td>\n",
       "      <td>1.516235e-01</td>\n",
       "      <td>1.230162e-01</td>\n",
       "      <td>1.389859e-01</td>\n",
       "      <td>1.191419e-02</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>554.123887</td>\n",
       "      <td>6.241637</td>\n",
       "      <td>11.457076</td>\n",
       "      <td>0.222721</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>0.1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'model__loss': 'mean_squared_error', 'model__...</td>\n",
       "      <td>-2.035423e+00</td>\n",
       "      <td>-1.184740e+00</td>\n",
       "      <td>-1.050251e-01</td>\n",
       "      <td>-1.108396e+00</td>\n",
       "      <td>7.899286e-01</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>556.392932</td>\n",
       "      <td>3.904537</td>\n",
       "      <td>14.404374</td>\n",
       "      <td>4.334848</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'model__loss': 'mean_squared_error', 'model__...</td>\n",
       "      <td>-2.882924e+00</td>\n",
       "      <td>-4.290385e+01</td>\n",
       "      <td>-1.067719e+01</td>\n",
       "      <td>-1.882132e+01</td>\n",
       "      <td>1.732366e+01</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>323.568527</td>\n",
       "      <td>41.555481</td>\n",
       "      <td>3.728820</td>\n",
       "      <td>1.024217</td>\n",
       "      <td>mean_squared_logarithmic_error</td>\n",
       "      <td>1.0</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>{'model__loss': 'mean_squared_logarithmic_erro...</td>\n",
       "      <td>-2.449437e+13</td>\n",
       "      <td>-7.500737e+13</td>\n",
       "      <td>-2.864962e+12</td>\n",
       "      <td>-3.412223e+13</td>\n",
       "      <td>3.022861e+13</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0     297.179786     18.314385         3.105154        0.092687   \n",
       "1     286.886634      2.239152         2.950888        0.088533   \n",
       "2     292.375545     21.244648         2.850126        0.047195   \n",
       "3     559.648948      7.136772        14.748720        4.118017   \n",
       "4     144.686605      0.774154         3.621450        1.096722   \n",
       "5     173.096858      1.053130         1.892477        0.032001   \n",
       "6     148.635358      1.662715         3.796727        0.976431   \n",
       "7     554.123887      6.241637        11.457076        0.222721   \n",
       "8     556.392932      3.904537        14.404374        4.334848   \n",
       "9     323.568527     41.555481         3.728820        1.024217   \n",
       "\n",
       "                param_model__loss param_model__learningRate  \\\n",
       "0  mean_squared_logarithmic_error                       1.0   \n",
       "1  mean_squared_logarithmic_error                      0.01   \n",
       "2              mean_squared_error                      0.01   \n",
       "3              mean_squared_error                      0.01   \n",
       "4             mean_absolute_error                       1.0   \n",
       "5             mean_absolute_error                      0.01   \n",
       "6             mean_absolute_error                      0.01   \n",
       "7              mean_squared_error                       0.1   \n",
       "8              mean_squared_error                       1.0   \n",
       "9  mean_squared_logarithmic_error                       1.0   \n",
       "\n",
       "  param_model__activation param_epochs param_batch_size  \\\n",
       "0                 sigmoid           20               50   \n",
       "1                 sigmoid           20               50   \n",
       "2                    relu           20               50   \n",
       "3                 sigmoid           10               10   \n",
       "4                    relu           10               50   \n",
       "5                 sigmoid           20              100   \n",
       "6                 sigmoid           10               50   \n",
       "7                 sigmoid           10               10   \n",
       "8                 sigmoid           10               10   \n",
       "9                    relu           20               50   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'model__loss': 'mean_squared_logarithmic_erro...      -2.160391e+05   \n",
       "1  {'model__loss': 'mean_squared_logarithmic_erro...      -4.943135e+00   \n",
       "2  {'model__loss': 'mean_squared_error', 'model__...       2.680709e-01   \n",
       "3  {'model__loss': 'mean_squared_error', 'model__...       2.690072e-01   \n",
       "4  {'model__loss': 'mean_absolute_error', 'model_...      -2.318015e-02   \n",
       "5  {'model__loss': 'mean_absolute_error', 'model_...       1.368626e-01   \n",
       "6  {'model__loss': 'mean_absolute_error', 'model_...       1.423180e-01   \n",
       "7  {'model__loss': 'mean_squared_error', 'model__...      -2.035423e+00   \n",
       "8  {'model__loss': 'mean_squared_error', 'model__...      -2.882924e+00   \n",
       "9  {'model__loss': 'mean_squared_logarithmic_erro...      -2.449437e+13   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0      -2.207842e+05      -1.381446e+05    -1.916560e+05    3.788778e+04   \n",
       "1      -8.525162e+00      -3.236371e+00    -5.568223e+00    2.203918e+00   \n",
       "2       2.772674e-01       2.797438e-01     2.750274e-01    5.021796e-03   \n",
       "3       1.726895e-01      -3.979742e-02     1.339665e-01    1.290082e-01   \n",
       "4      -6.933849e-02      -2.021837e-01    -9.823410e-02    7.588053e-02   \n",
       "5       1.492303e-01       1.426605e-01     1.429178e-01    5.052350e-03   \n",
       "6       1.516235e-01       1.230162e-01     1.389859e-01    1.191419e-02   \n",
       "7      -1.184740e+00      -1.050251e-01    -1.108396e+00    7.899286e-01   \n",
       "8      -4.290385e+01      -1.067719e+01    -1.882132e+01    1.732366e+01   \n",
       "9      -7.500737e+13      -2.864962e+12    -3.412223e+13    3.022861e+13   \n",
       "\n",
       "   rank_test_score  \n",
       "0                9  \n",
       "1                7  \n",
       "2                1  \n",
       "3                4  \n",
       "4                5  \n",
       "5                2  \n",
       "6                3  \n",
       "7                6  \n",
       "8                8  \n",
       "9               10  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO-DO: Arrange this in a good table format\n",
    "\n",
    "all_results = pd.DataFrame(bestModel.cv_results_)\n",
    "# all_results[\"params_stringified\"] = all_results[\"params\"].applyMap(dictToStr)\n",
    "all_results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f180d2b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1911/1911 [==============================] - 2s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "yPred = tunedNN.predict(XTestScaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6b896e58",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mean_absolute_error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12988/1719431704.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mTunedMSEloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myTest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myPred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mTunedRMSEloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myTest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myPred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mTunedMAE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myTest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myPred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTunedMSEloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTunedRMSEloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTunedMAE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mean_absolute_error' is not defined"
     ]
    }
   ],
   "source": [
    "# Calculate loss for regression\n",
    "TunedMSEloss = mean_squared_error(yTest, yPred)\n",
    "TunedRMSEloss = mean_squared_error(yTest, yPred, squared=False)\n",
    "TunedMAE = mean_absolute_error(yTest, yPred)\n",
    "\n",
    "print(TunedMSEloss, TunedRMSEloss, TunedMAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fd95c0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: NN_Model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: NN_Model/assets\n"
     ]
    }
   ],
   "source": [
    "tunedNN.model_.save(\"NN_Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e747f84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
