{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52cfa135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install via terminal in ubuntu\n",
    "# sudo apt install pip\n",
    "# pip install scikit-learn pandas seaborn tensorflow scikeras\n",
    "# !pip install keras-tuner --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7a5c8fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'local[*]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sc master - running locally\n",
    "sc.master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b84fce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcf71413",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-09 21:05:42.594938: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-09 21:05:43.134645: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-09 21:05:43.134680: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-09 21:05:43.135646: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-09 21:05:43.411780: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-09 21:05:43.412920: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-09 21:05:44.710922: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04f8560",
   "metadata": {},
   "source": [
    "## Data reading and final cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d636740c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-09 21:05:52,653 WARN util.package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>status</th>\n",
       "      <th>runtime</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release_year</th>\n",
       "      <th>genre_count</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Family</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>History</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Music</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Science Fiction</th>\n",
       "      <th>TV Movie</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Inception</td>\n",
       "      <td>8.364</td>\n",
       "      <td>Released</td>\n",
       "      <td>148</td>\n",
       "      <td>83.952</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Interstellar</td>\n",
       "      <td>8.417</td>\n",
       "      <td>Released</td>\n",
       "      <td>169</td>\n",
       "      <td>140.241</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>8.512</td>\n",
       "      <td>Released</td>\n",
       "      <td>152</td>\n",
       "      <td>130.643</td>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Avatar</td>\n",
       "      <td>7.573</td>\n",
       "      <td>Released</td>\n",
       "      <td>162</td>\n",
       "      <td>79.932</td>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Avengers</td>\n",
       "      <td>7.71</td>\n",
       "      <td>Released</td>\n",
       "      <td>143</td>\n",
       "      <td>98.082</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             title vote_average    status runtime popularity release_year  \\\n",
       "0        Inception        8.364  Released     148     83.952         2010   \n",
       "1     Interstellar        8.417  Released     169    140.241         2014   \n",
       "2  The Dark Knight        8.512  Released     152    130.643         2008   \n",
       "3           Avatar        7.573  Released     162     79.932         2009   \n",
       "4     The Avengers         7.71  Released     143     98.082         2012   \n",
       "\n",
       "  genre_count  Action Adventure  Animation  Comedy  Crime  Documentary  Drama  \\\n",
       "0           3     1.0         1          0     0.0      0            0      0   \n",
       "1           3     0.0         1          0     0.0      0            0      1   \n",
       "2           4     1.0         0          0     0.0      1            0      1   \n",
       "3           4     1.0         1          0     0.0      0            0      0   \n",
       "4           3     1.0         1          0     0.0      0            0      0   \n",
       "\n",
       "   Family  Fantasy  History  Horror  Music  Mystery  Romance  Science Fiction  \\\n",
       "0       0        0        0       0      0        0        0                1   \n",
       "1       0        0        0       0      0        0        0                1   \n",
       "2       0        0        0       0      0        0        0                0   \n",
       "3       0        1        0       0      0        0        0                1   \n",
       "4       0        0        0       0      0        0        0                1   \n",
       "\n",
       "   TV Movie  Thriller  War  Western  \n",
       "0         0         0    0        0  \n",
       "1         0         0    0        0  \n",
       "2         0         1    0        0  \n",
       "3         0         0    0        0  \n",
       "4         0         0    0        0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the cleaned dataset from hadoop. \n",
    "# This has been renamed from part-00000-cdda873a-60d8-4ecc-b275-06323eb00068-c000.csv to cleaned_TMBD_dataset\n",
    "dataPath = \"/CA1/data/cleaned/cleaned_TMDB_dataset.csv\"\n",
    "cleanedDF = spark.read \\\n",
    "    .option(\"multiline\", \"true\") \\\n",
    "    .option(\"quote\", '\"') \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"escape\", \"\\\\\") \\\n",
    "    .option(\"escape\", '\"') \\\n",
    "    .csv(dataPath, header = True, inferSchema = True)\n",
    "cleanedDF.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6886029",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- vote_average: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- runtime: string (nullable = true)\n",
      " |-- popularity: string (nullable = true)\n",
      " |-- release_year: string (nullable = true)\n",
      " |-- genre_count: string (nullable = true)\n",
      " |-- Action: double (nullable = true)\n",
      " |-- Adventure: string (nullable = true)\n",
      " |-- Animation: integer (nullable = true)\n",
      " |-- Comedy: double (nullable = true)\n",
      " |-- Crime: integer (nullable = true)\n",
      " |-- Documentary: integer (nullable = true)\n",
      " |-- Drama: integer (nullable = true)\n",
      " |-- Family: integer (nullable = true)\n",
      " |-- Fantasy: integer (nullable = true)\n",
      " |-- History: integer (nullable = true)\n",
      " |-- Horror: integer (nullable = true)\n",
      " |-- Music: integer (nullable = true)\n",
      " |-- Mystery: integer (nullable = true)\n",
      " |-- Romance: integer (nullable = true)\n",
      " |-- Science Fiction: integer (nullable = true)\n",
      " |-- TV Movie: integer (nullable = true)\n",
      " |-- Thriller: integer (nullable = true)\n",
      " |-- War: integer (nullable = true)\n",
      " |-- Western: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleanedDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ebeeb0",
   "metadata": {},
   "source": [
    "Since there are incorrectly typed columns in the schema, it must be set to the correct type first to prevent issues in the training. String columns will now be removed so only numerical columns are left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa6fc0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- vote_average: float (nullable = true)\n",
      " |-- runtime: integer (nullable = true)\n",
      " |-- popularity: float (nullable = true)\n",
      " |-- release_year: integer (nullable = true)\n",
      " |-- genre_count: integer (nullable = true)\n",
      " |-- Action: integer (nullable = true)\n",
      " |-- Adventure: integer (nullable = true)\n",
      " |-- Animation: integer (nullable = true)\n",
      " |-- comedy: integer (nullable = true)\n",
      " |-- Crime: integer (nullable = true)\n",
      " |-- Documentary: integer (nullable = true)\n",
      " |-- Drama: integer (nullable = true)\n",
      " |-- Family: integer (nullable = true)\n",
      " |-- Fantasy: integer (nullable = true)\n",
      " |-- History: integer (nullable = true)\n",
      " |-- Horror: integer (nullable = true)\n",
      " |-- Music: integer (nullable = true)\n",
      " |-- Mystery: integer (nullable = true)\n",
      " |-- Romance: integer (nullable = true)\n",
      " |-- Science Fiction: integer (nullable = true)\n",
      " |-- TV Movie: integer (nullable = true)\n",
      " |-- Thriller: integer (nullable = true)\n",
      " |-- War: integer (nullable = true)\n",
      " |-- Western: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleanedDF = cleanedDF.withColumn(\"runtime\", cleanedDF[\"runtime\"].cast(\"int\"))\n",
    "cleanedDF = cleanedDF.withColumn(\"popularity\", cleanedDF[\"popularity\"].cast(\"float\"))\n",
    "cleanedDF = cleanedDF.withColumn(\"release_year\", cleanedDF[\"release_year\"].cast(\"int\"))\n",
    "cleanedDF = cleanedDF.withColumn(\"Action\", cleanedDF[\"Action\"].cast(\"int\"))\n",
    "cleanedDF = cleanedDF.withColumn(\"Adventure\", cleanedDF[\"Adventure\"].cast(\"int\"))\n",
    "cleanedDF = cleanedDF.withColumn(\"Animation\", cleanedDF[\"Animation\"].cast(\"int\"))\n",
    "cleanedDF = cleanedDF.withColumn(\"Crime\", cleanedDF[\"Crime\"].cast(\"int\"))\n",
    "cleanedDF = cleanedDF.withColumn(\"vote_average\", cleanedDF[\"vote_average\"].cast(\"float\"))\n",
    "cleanedDF = cleanedDF.withColumn(\"genre_count\", cleanedDF[\"genre_count\"].cast(\"int\"))\n",
    "cleanedDF = cleanedDF.withColumn(\"comedy\", cleanedDF[\"comedy\"].cast(\"int\"))\n",
    "\n",
    "\n",
    "cleanedDF = cleanedDF.drop(\"title\")\n",
    "cleanedDF = cleanedDF.drop(\"status\")\n",
    "# cleanedDF = cleanedDF.drop(\"release_year\")\n",
    "# cleanedDF = cleanedDF.drop(\"popularity\")\n",
    "cleanedDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1c260e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vote_average</th>\n",
       "      <th>runtime</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release_year</th>\n",
       "      <th>genre_count</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Family</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>History</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Music</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Science Fiction</th>\n",
       "      <th>TV Movie</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.364</td>\n",
       "      <td>148.0</td>\n",
       "      <td>83.952003</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.417</td>\n",
       "      <td>169.0</td>\n",
       "      <td>140.240997</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.512</td>\n",
       "      <td>152.0</td>\n",
       "      <td>130.643005</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.573</td>\n",
       "      <td>162.0</td>\n",
       "      <td>79.931999</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.710</td>\n",
       "      <td>143.0</td>\n",
       "      <td>98.082001</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vote_average  runtime  popularity  release_year  genre_count  Action  \\\n",
       "0         8.364    148.0   83.952003        2010.0          3.0       1   \n",
       "1         8.417    169.0  140.240997        2014.0          3.0       0   \n",
       "2         8.512    152.0  130.643005        2008.0          4.0       1   \n",
       "3         7.573    162.0   79.931999        2009.0          4.0       1   \n",
       "4         7.710    143.0   98.082001        2012.0          3.0       1   \n",
       "\n",
       "   Adventure  Animation  comedy  Crime  Documentary  Drama  Family  Fantasy  \\\n",
       "0        1.0          0       0      0            0      0       0        0   \n",
       "1        1.0          0       0      0            0      1       0        0   \n",
       "2        0.0          0       0      1            0      1       0        0   \n",
       "3        1.0          0       0      0            0      0       0        1   \n",
       "4        1.0          0       0      0            0      0       0        0   \n",
       "\n",
       "   History  Horror  Music  Mystery  Romance  Science Fiction  TV Movie  \\\n",
       "0        0       0      0        0        0                1         0   \n",
       "1        0       0      0        0        0                1         0   \n",
       "2        0       0      0        0        0                0         0   \n",
       "3        0       0      0        0        0                1         0   \n",
       "4        0       0      0        0        0                1         0   \n",
       "\n",
       "   Thriller  War  Western  \n",
       "0         0    0        0  \n",
       "1         0    0        0  \n",
       "2         1    0        0  \n",
       "3         0    0        0  \n",
       "4         0    0        0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanedDF.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46e609a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cleanedPandasDF = cleanedDF.toPandas()\n",
    "# X = cleanedDF.columns[0]\n",
    "# independentColumns = cleanedDF.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2229afc4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cleanedPandasDF = cleanedPandasDF.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bbba40e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(477722, 24)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanedPandasDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4652748",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedPandasDF[\"Adventure\"] = cleanedPandasDF[\"Adventure\"].astype(float)\n",
    "X = cleanedPandasDF.drop(columns=[cleanedDF.columns[0]])\n",
    "y = cleanedPandasDF[cleanedDF.columns[0]]\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0512ae42",
   "metadata": {},
   "source": [
    "### Scaling the data\n",
    "In the EDA, the data contains outliers hence it's not applicable to use standard scaler. Robust scaler was used instead since it can handle outlier very well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6ec043b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "# scaler = StandardScaler()\n",
    "XTrainScaled = scaler.fit_transform(XTrain)\n",
    "XTestScaled = scaler.transform(XTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c604d138",
   "metadata": {},
   "source": [
    "### Function for creating model\n",
    "It has 4 layers with 2 hidden layers since the problem is not complex. The hidden layers have 4-7 neurons (depending on the hyperparameters) which is based on the rule where each hidden layer should have a sqrt(input * output).\n",
    "\n",
    "Due to data being sparse because of one-hot encoding, Adadelta was used (which is more efficient than Adagrad). For the loss function, mean absolute error was used due to presence of outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77a6b7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel(\n",
    "    activation = \"relu\", \n",
    "    learningRate = 0.1, \n",
    "    loss = \"mean_squared_logarithmic_error\"\n",
    "): \n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Input(shape = (XTrainScaled.shape[1],)))\n",
    "    model.add(keras.layers.Dense(\n",
    "        units = 512, \n",
    "        kernel_initializer='normal', \n",
    "        use_bias = True,\n",
    "        activation=activation))\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "    model.add(keras.layers.Dense(\n",
    "        units = 512, \n",
    "        kernel_initializer='normal', \n",
    "        use_bias = True,\n",
    "        activation=activation))\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "#     model.add(keras.layers.Dense(\n",
    "#         hiddenUnits, \n",
    "#         kernel_initializer='normal', \n",
    "#         activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(\n",
    "        1\n",
    "        ))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            learning_rate = learningRate),\n",
    "        loss=loss, \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "        \n",
    "    return model\n",
    "\n",
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Error [MPG]')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "def plot_accuracy(history):\n",
    "    plt.plot(history.history['accuracy'], label='accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy [MPG]')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8638a6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialModel = createModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8b15eae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6115/6115 [==============================] - 19s 3ms/step - loss: 1.9168 - accuracy: 0.4562 - val_loss: 1.9852 - val_accuracy: 0.4655\n",
      "Epoch 2/10\n",
      "6115/6115 [==============================] - 16s 3ms/step - loss: 1.9830 - accuracy: 0.4656 - val_loss: 1.9852 - val_accuracy: 0.4655\n",
      "Epoch 3/10\n",
      "6115/6115 [==============================] - 16s 3ms/step - loss: 1.9831 - accuracy: 0.4656 - val_loss: 1.9852 - val_accuracy: 0.4655\n",
      "Epoch 4/10\n",
      "6115/6115 [==============================] - 16s 3ms/step - loss: 1.9830 - accuracy: 0.4656 - val_loss: 1.9852 - val_accuracy: 0.4655\n",
      "Epoch 5/10\n",
      "6115/6115 [==============================] - 16s 3ms/step - loss: 1.9830 - accuracy: 0.4656 - val_loss: 1.9852 - val_accuracy: 0.4655\n",
      "Epoch 6/10\n",
      "6115/6115 [==============================] - 17s 3ms/step - loss: 1.9830 - accuracy: 0.4656 - val_loss: 1.9852 - val_accuracy: 0.4655\n",
      "Epoch 7/10\n",
      "6115/6115 [==============================] - 16s 3ms/step - loss: 1.9830 - accuracy: 0.4656 - val_loss: 1.9852 - val_accuracy: 0.4655\n",
      "Epoch 8/10\n",
      "6115/6115 [==============================] - 18s 3ms/step - loss: 1.9830 - accuracy: 0.4656 - val_loss: 1.9852 - val_accuracy: 0.4655\n",
      "Epoch 9/10\n",
      "6115/6115 [==============================] - 16s 3ms/step - loss: 1.9830 - accuracy: 0.4656 - val_loss: 1.9852 - val_accuracy: 0.4655\n",
      "Epoch 10/10\n",
      "6115/6115 [==============================] - 16s 3ms/step - loss: 1.9830 - accuracy: 0.4656 - val_loss: 1.9852 - val_accuracy: 0.4655\n"
     ]
    }
   ],
   "source": [
    "history = initialModel.fit(\n",
    "    XTrainScaled,\n",
    "    yTrain,\n",
    "    validation_split = 0.2,\n",
    "    verbose = 1, epochs = 10,\n",
    "    batch_size = 50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bfa8e0d1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1f0958d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a25149b9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2986/2986 [==============================] - 3s 913us/step\n"
     ]
    }
   ],
   "source": [
    "initialYPred = initialModel.predict(XTestScaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f33e60a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1486517400.0 38555.38 16944.742\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss, mean_squared_error, mean_absolute_error\n",
    "# Calculate loss for regression\n",
    "InitialMSEloss = mean_squared_error(yTest, initialYPred)\n",
    "InitialRMSEloss = mean_squared_error(yTest, initialYPred, squared=False)\n",
    "InitialMAE = mean_absolute_error(yTest, initialYPred)\n",
    "\n",
    "print(InitialMSEloss, InitialRMSEloss, InitialMAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e5a4d8",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2db4c30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = dict(\n",
    "    model__activation = [\"relu\", \"sigmoid\"],\n",
    "    batch_size = np.array([10, 50, 100]),\n",
    "    epochs = np.array([10, 20]),\n",
    "    model__learningRate = np.array([0.1, 0.01, 1]),\n",
    "    model__loss = [\"mean_squared_logarithmic_error\", \"mean_squared_error\", \"mean_absolute_error\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "403b4e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "model = KerasRegressor(build_fn=createModel,verbose=1)\n",
    "\n",
    "bestModel = RandomizedSearchCV(estimator = model,\n",
    "                               param_distributions = parameters,\n",
    "                               verbose = 1,\n",
    "                               cv = 3\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "925c834d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Epoch 1/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 2.0688 - accuracy: 0.4645\n",
      "Epoch 2/20\n",
      "5096/5096 [==============================] - 13s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 3/20\n",
      "5096/5096 [==============================] - 13s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 4/20\n",
      "5096/5096 [==============================] - 13s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 5/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 6/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 7/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 8/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 9/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 10/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 11/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 12/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 13/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 14/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 15/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 16/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 17/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 18/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 19/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 20/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "2548/2548 [==============================] - 3s 1ms/step\n",
      "Epoch 1/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9926 - accuracy: 0.4650\n",
      "Epoch 2/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 3/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 4/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 5/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 6/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 7/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 8/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 9/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 10/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 11/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 12/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 13/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 14/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 15/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 16/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 17/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 18/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 19/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 20/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "2548/2548 [==============================] - 3s 1ms/step\n",
      "Epoch 1/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 2.1817 - accuracy: 0.4621\n",
      "Epoch 2/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 3/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 4/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 5/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 6/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 7/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 8/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 9/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 10/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 11/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 12/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 13/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 14/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 15/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 16/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 17/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 18/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 19/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 20/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "2548/2548 [==============================] - 3s 1ms/step\n",
      "Epoch 1/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9816 - accuracy: 0.4659\n",
      "Epoch 2/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 3/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 4/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 5/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 6/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 7/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 8/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 9/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 10/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 11/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 12/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 13/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 14/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 15/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 16/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 17/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 18/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 19/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 20/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "2548/2548 [==============================] - 3s 1ms/step\n",
      "Epoch 1/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9878 - accuracy: 0.4640\n",
      "Epoch 2/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 3/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 4/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 5/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 6/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 7/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 8/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 9/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 10/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 11/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 12/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 13/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 14/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 15/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 16/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 17/20\n",
      "5096/5096 [==============================] - 16s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 18/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 19/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 20/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "2548/2548 [==============================] - 3s 1ms/step\n",
      "Epoch 1/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9841 - accuracy: 0.4646\n",
      "Epoch 2/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 3/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 4/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 5/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 6/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 7/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 8/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 9/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 10/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 11/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 12/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 13/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 14/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 15/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 16/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 17/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 18/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 19/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 20/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "2548/2548 [==============================] - 3s 1ms/step\n",
      "Epoch 1/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 15.4939 - accuracy: 0.0166\n",
      "Epoch 2/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 8.1267 - accuracy: 0.0238\n",
      "Epoch 3/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 8.2367 - accuracy: 0.0229\n",
      "Epoch 4/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 8.1040 - accuracy: 0.0226\n",
      "Epoch 5/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 8.2618 - accuracy: 0.0243\n",
      "Epoch 6/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.9871 - accuracy: 0.0210\n",
      "Epoch 7/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8701 - accuracy: 0.0200\n",
      "Epoch 8/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 8.7501 - accuracy: 0.0186\n",
      "Epoch 9/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 9.1569 - accuracy: 0.0174\n",
      "Epoch 10/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8582 - accuracy: 0.0145\n",
      "Epoch 11/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8646 - accuracy: 0.0174\n",
      "Epoch 12/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8698 - accuracy: 0.0148\n",
      "Epoch 13/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 8.0394 - accuracy: 0.0140\n",
      "Epoch 14/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8519 - accuracy: 0.0146\n",
      "Epoch 15/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8329 - accuracy: 0.0153\n",
      "Epoch 16/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8344 - accuracy: 0.0151\n",
      "Epoch 17/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8535 - accuracy: 0.0155\n",
      "Epoch 18/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 8.0079 - accuracy: 0.0129\n",
      "Epoch 19/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8591 - accuracy: 0.0135\n",
      "Epoch 20/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 7.8409 - accuracy: 0.0133\n",
      "2548/2548 [==============================] - 3s 993us/step\n",
      "Epoch 1/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 10.9459 - accuracy: 0.0171\n",
      "Epoch 2/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 8.4607 - accuracy: 0.0230\n",
      "Epoch 3/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 8.4625 - accuracy: 0.0233\n",
      "Epoch 4/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.9146 - accuracy: 0.0188\n",
      "Epoch 5/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 8.0442 - accuracy: 0.0183\n",
      "Epoch 6/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.9377 - accuracy: 0.0180\n",
      "Epoch 7/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8690 - accuracy: 0.0168\n",
      "Epoch 8/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8662 - accuracy: 0.0174\n",
      "Epoch 9/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.9193 - accuracy: 0.0155\n",
      "Epoch 10/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.9225 - accuracy: 0.0146\n",
      "Epoch 11/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 8.1047 - accuracy: 0.0163\n",
      "Epoch 12/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8928 - accuracy: 0.0167\n",
      "Epoch 13/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8694 - accuracy: 0.0165\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8794 - accuracy: 0.0148\n",
      "Epoch 15/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8910 - accuracy: 0.0152\n",
      "Epoch 16/20\n",
      "5096/5096 [==============================] - 13s 3ms/step - loss: 7.9155 - accuracy: 0.0149\n",
      "Epoch 17/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8809 - accuracy: 0.0148\n",
      "Epoch 18/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8583 - accuracy: 0.0146\n",
      "Epoch 19/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8402 - accuracy: 0.0152\n",
      "Epoch 20/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8354 - accuracy: 0.0142\n",
      "2548/2548 [==============================] - 3s 978us/step\n",
      "Epoch 1/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 33.5028 - accuracy: 0.0212\n",
      "Epoch 2/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 8.3152 - accuracy: 0.0335\n",
      "Epoch 3/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 9.2633 - accuracy: 0.0310\n",
      "Epoch 4/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 8.3959 - accuracy: 0.0273\n",
      "Epoch 5/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 8.0825 - accuracy: 0.0284\n",
      "Epoch 6/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 9.2909 - accuracy: 0.0271\n",
      "Epoch 7/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.9703 - accuracy: 0.0284\n",
      "Epoch 8/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 8.2842 - accuracy: 0.0283\n",
      "Epoch 9/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 8.2682 - accuracy: 0.0235\n",
      "Epoch 10/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8999 - accuracy: 0.0227\n",
      "Epoch 11/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 7.8635 - accuracy: 0.0224\n",
      "Epoch 12/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8506 - accuracy: 0.0224\n",
      "Epoch 13/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.9062 - accuracy: 0.0219\n",
      "Epoch 14/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.9428 - accuracy: 0.0202\n",
      "Epoch 15/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8368 - accuracy: 0.0190\n",
      "Epoch 16/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8326 - accuracy: 0.0179\n",
      "Epoch 17/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 8.1779 - accuracy: 0.0198\n",
      "Epoch 18/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8266 - accuracy: 0.0197\n",
      "Epoch 19/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8320 - accuracy: 0.0186\n",
      "Epoch 20/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 7.8544 - accuracy: 0.0187\n",
      "2548/2548 [==============================] - 3s 1ms/step\n",
      "Epoch 1/10\n",
      "25479/25479 [==============================] - 57s 2ms/step - loss: 8.6388 - accuracy: 0.0326\n",
      "Epoch 2/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 8.4616 - accuracy: 0.0376\n",
      "Epoch 3/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 8.4368 - accuracy: 0.0418\n",
      "Epoch 4/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 8.4206 - accuracy: 0.0478\n",
      "Epoch 5/10\n",
      "25479/25479 [==============================] - 54s 2ms/step - loss: 8.3895 - accuracy: 0.0494\n",
      "Epoch 6/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 8.3745 - accuracy: 0.0501\n",
      "Epoch 7/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 8.3328 - accuracy: 0.0465\n",
      "Epoch 8/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 8.3537 - accuracy: 0.0491\n",
      "Epoch 9/10\n",
      "25479/25479 [==============================] - 53s 2ms/step - loss: 8.3321 - accuracy: 0.0525\n",
      "Epoch 10/10\n",
      "25479/25479 [==============================] - 54s 2ms/step - loss: 8.3110 - accuracy: 0.0502\n",
      "12740/12740 [==============================] - 10s 812us/step\n",
      "Epoch 1/10\n",
      "25479/25479 [==============================] - 58s 2ms/step - loss: 8.7813 - accuracy: 0.0367\n",
      "Epoch 2/10\n",
      "25479/25479 [==============================] - 57s 2ms/step - loss: 8.6088 - accuracy: 0.0468\n",
      "Epoch 3/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 8.5502 - accuracy: 0.0474\n",
      "Epoch 4/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 8.4781 - accuracy: 0.0459\n",
      "Epoch 5/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 8.4808 - accuracy: 0.0512\n",
      "Epoch 6/10\n",
      "25479/25479 [==============================] - 57s 2ms/step - loss: 8.4341 - accuracy: 0.0524\n",
      "Epoch 7/10\n",
      "25479/25479 [==============================] - 61s 2ms/step - loss: 8.4361 - accuracy: 0.0508\n",
      "Epoch 8/10\n",
      "25479/25479 [==============================] - 57s 2ms/step - loss: 8.4078 - accuracy: 0.0536\n",
      "Epoch 9/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 8.4185 - accuracy: 0.0542\n",
      "Epoch 10/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 8.3981 - accuracy: 0.0537\n",
      "12740/12740 [==============================] - 10s 798us/step\n",
      "Epoch 1/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 8.7296 - accuracy: 0.0349\n",
      "Epoch 2/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 8.5634 - accuracy: 0.0451\n",
      "Epoch 3/10\n",
      "25479/25479 [==============================] - 57s 2ms/step - loss: 8.4989 - accuracy: 0.0467\n",
      "Epoch 4/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 8.4328 - accuracy: 0.0467\n",
      "Epoch 5/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 8.4224 - accuracy: 0.0489\n",
      "Epoch 6/10\n",
      "25479/25479 [==============================] - 57s 2ms/step - loss: 8.4157 - accuracy: 0.0502\n",
      "Epoch 7/10\n",
      "25479/25479 [==============================] - 59s 2ms/step - loss: 8.3996 - accuracy: 0.0507\n",
      "Epoch 8/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 8.3776 - accuracy: 0.0514\n",
      "Epoch 9/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 8.3927 - accuracy: 0.0533\n",
      "Epoch 10/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 8.3784 - accuracy: 0.0538\n",
      "12740/12740 [==============================] - 10s 796us/step\n",
      "Epoch 1/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 48.3800 - accuracy: 0.0200\n",
      "Epoch 2/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 3.0898 - accuracy: 0.0198\n",
      "Epoch 3/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 3.0810 - accuracy: 0.0211\n",
      "Epoch 4/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 3.0791 - accuracy: 0.0203\n",
      "Epoch 5/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 3.0810 - accuracy: 0.0191\n",
      "Epoch 6/10\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 3.0780 - accuracy: 0.0225\n",
      "Epoch 7/10\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 3.0843 - accuracy: 0.0207\n",
      "Epoch 8/10\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 3.0835 - accuracy: 0.0188\n",
      "Epoch 9/10\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 3.0828 - accuracy: 0.0209\n",
      "Epoch 10/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 3.0998 - accuracy: 0.0158\n",
      "2548/2548 [==============================] - 3s 1ms/step\n",
      "Epoch 1/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 50.0403 - accuracy: 0.0223\n",
      "Epoch 2/10\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 3.0835 - accuracy: 0.0203\n",
      "Epoch 3/10\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 3.0867 - accuracy: 0.0171\n",
      "Epoch 4/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 3.0839 - accuracy: 0.0171\n",
      "Epoch 5/10\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 3.0858 - accuracy: 0.0200\n",
      "Epoch 6/10\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 3.0862 - accuracy: 0.0178\n",
      "Epoch 7/10\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 3.1603 - accuracy: 0.0169\n",
      "Epoch 8/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 3.0832 - accuracy: 0.0203\n",
      "Epoch 9/10\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 3.0856 - accuracy: 0.0184\n",
      "Epoch 10/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 3.0832 - accuracy: 0.0188\n",
      "2548/2548 [==============================] - 3s 1ms/step\n",
      "Epoch 1/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 100.6689 - accuracy: 0.0204\n",
      "Epoch 2/10\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 3.3943 - accuracy: 0.0176\n",
      "Epoch 3/10\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 3.0820 - accuracy: 0.0228\n",
      "Epoch 4/10\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 3.0808 - accuracy: 0.0234\n",
      "Epoch 5/10\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 3.0839 - accuracy: 0.0215\n",
      "Epoch 6/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 3.0777 - accuracy: 0.0199\n",
      "Epoch 7/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 3.0805 - accuracy: 0.0203\n",
      "Epoch 8/10\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 3.1081 - accuracy: 0.0191\n",
      "Epoch 9/10\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 3.0804 - accuracy: 0.0208\n",
      "Epoch 10/10\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 3.0818 - accuracy: 0.0169\n",
      "2548/2548 [==============================] - 3s 981us/step\n",
      "Epoch 1/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 2.0328 - accuracy: 0.3234\n",
      "Epoch 2/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.9446 - accuracy: 0.3557\n",
      "Epoch 3/20\n",
      "2548/2548 [==============================] - 8s 3ms/step - loss: 1.9161 - accuracy: 0.3486\n",
      "Epoch 4/20\n",
      "2548/2548 [==============================] - 9s 4ms/step - loss: 1.8933 - accuracy: 0.3472\n",
      "Epoch 5/20\n",
      "2548/2548 [==============================] - 9s 4ms/step - loss: 1.8792 - accuracy: 0.3523\n",
      "Epoch 6/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8655 - accuracy: 0.3530\n",
      "Epoch 7/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8550 - accuracy: 0.3529\n",
      "Epoch 8/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8466 - accuracy: 0.3529\n",
      "Epoch 9/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8353 - accuracy: 0.3546\n",
      "Epoch 10/20\n",
      "2548/2548 [==============================] - 8s 3ms/step - loss: 1.8278 - accuracy: 0.3556\n",
      "Epoch 11/20\n",
      "2548/2548 [==============================] - 8s 3ms/step - loss: 1.8237 - accuracy: 0.3571\n",
      "Epoch 12/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8189 - accuracy: 0.3570\n",
      "Epoch 13/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8182 - accuracy: 0.3573\n",
      "Epoch 14/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8138 - accuracy: 0.3573\n",
      "Epoch 15/20\n",
      "2548/2548 [==============================] - 8s 3ms/step - loss: 1.8096 - accuracy: 0.3576\n",
      "Epoch 16/20\n",
      "2548/2548 [==============================] - 9s 4ms/step - loss: 1.8062 - accuracy: 0.3584\n",
      "Epoch 17/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8043 - accuracy: 0.3595\n",
      "Epoch 18/20\n",
      "2548/2548 [==============================] - 8s 3ms/step - loss: 1.8008 - accuracy: 0.3585\n",
      "Epoch 19/20\n",
      "2548/2548 [==============================] - 8s 3ms/step - loss: 1.8030 - accuracy: 0.3594\n",
      "Epoch 20/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.7994 - accuracy: 0.3595\n",
      "1274/1274 [==============================] - 2s 1ms/step\n",
      "Epoch 1/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 2.0474 - accuracy: 0.3148\n",
      "Epoch 2/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.9271 - accuracy: 0.3457\n",
      "Epoch 3/20\n",
      "2548/2548 [==============================] - 9s 4ms/step - loss: 1.9140 - accuracy: 0.3455\n",
      "Epoch 4/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.9031 - accuracy: 0.3450\n",
      "Epoch 5/20\n",
      "2548/2548 [==============================] - 8s 3ms/step - loss: 1.8969 - accuracy: 0.3447\n",
      "Epoch 6/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8884 - accuracy: 0.3431\n",
      "Epoch 7/20\n",
      "2548/2548 [==============================] - 9s 4ms/step - loss: 1.8785 - accuracy: 0.3431\n",
      "Epoch 8/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8659 - accuracy: 0.3493\n",
      "Epoch 9/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8571 - accuracy: 0.3521\n",
      "Epoch 10/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8525 - accuracy: 0.3524\n",
      "Epoch 11/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8453 - accuracy: 0.3539\n",
      "Epoch 12/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8400 - accuracy: 0.3542\n",
      "Epoch 13/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8366 - accuracy: 0.3549\n",
      "Epoch 14/20\n",
      "2548/2548 [==============================] - 9s 4ms/step - loss: 1.8327 - accuracy: 0.3552\n",
      "Epoch 15/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8292 - accuracy: 0.3558\n",
      "Epoch 16/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8290 - accuracy: 0.3555\n",
      "Epoch 17/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8231 - accuracy: 0.3574\n",
      "Epoch 18/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8200 - accuracy: 0.3566\n",
      "Epoch 19/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8195 - accuracy: 0.3566\n",
      "Epoch 20/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8176 - accuracy: 0.3581\n",
      "1274/1274 [==============================] - 2s 1ms/step\n",
      "Epoch 1/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 2.0476 - accuracy: 0.3154\n",
      "Epoch 2/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.9336 - accuracy: 0.3559\n",
      "Epoch 3/20\n",
      "2548/2548 [==============================] - 8s 3ms/step - loss: 1.9111 - accuracy: 0.3509\n",
      "Epoch 4/20\n",
      "2548/2548 [==============================] - 8s 3ms/step - loss: 1.8921 - accuracy: 0.3529\n",
      "Epoch 5/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8798 - accuracy: 0.3550\n",
      "Epoch 6/20\n",
      "2548/2548 [==============================] - 8s 3ms/step - loss: 1.8701 - accuracy: 0.3557\n",
      "Epoch 7/20\n",
      "2548/2548 [==============================] - 8s 3ms/step - loss: 1.8578 - accuracy: 0.3566\n",
      "Epoch 8/20\n",
      "2548/2548 [==============================] - 8s 3ms/step - loss: 1.8501 - accuracy: 0.3568\n",
      "Epoch 9/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8442 - accuracy: 0.3578\n",
      "Epoch 10/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8366 - accuracy: 0.3589\n",
      "Epoch 11/20\n",
      "2548/2548 [==============================] - 8s 3ms/step - loss: 1.8311 - accuracy: 0.3586\n",
      "Epoch 12/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8261 - accuracy: 0.3594\n",
      "Epoch 13/20\n",
      "2548/2548 [==============================] - 8s 3ms/step - loss: 1.8230 - accuracy: 0.3608\n",
      "Epoch 14/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8209 - accuracy: 0.3610\n",
      "Epoch 15/20\n",
      "2548/2548 [==============================] - 8s 3ms/step - loss: 1.8162 - accuracy: 0.3617\n",
      "Epoch 16/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8156 - accuracy: 0.3602\n",
      "Epoch 17/20\n",
      "2548/2548 [==============================] - 8s 3ms/step - loss: 1.8116 - accuracy: 0.3615\n",
      "Epoch 18/20\n",
      "2548/2548 [==============================] - 8s 3ms/step - loss: 1.8105 - accuracy: 0.3622\n",
      "Epoch 19/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8107 - accuracy: 0.3618\n",
      "Epoch 20/20\n",
      "2548/2548 [==============================] - 9s 3ms/step - loss: 1.8076 - accuracy: 0.3624\n",
      "1274/1274 [==============================] - 2s 1ms/step\n",
      "Epoch 1/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 2.0214 - accuracy: 0.3294\n",
      "Epoch 2/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9446 - accuracy: 0.3472\n",
      "Epoch 3/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9189 - accuracy: 0.3437\n",
      "Epoch 4/10\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9027 - accuracy: 0.3445\n",
      "Epoch 5/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.8877 - accuracy: 0.3465\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.8726 - accuracy: 0.3506\n",
      "Epoch 7/10\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.8670 - accuracy: 0.3498\n",
      "Epoch 8/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.8582 - accuracy: 0.3497\n",
      "Epoch 9/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.8526 - accuracy: 0.3504\n",
      "Epoch 10/10\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.8433 - accuracy: 0.3524\n",
      "2548/2548 [==============================] - 3s 1ms/step\n",
      "Epoch 1/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 2.0194 - accuracy: 0.3190\n",
      "Epoch 2/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9355 - accuracy: 0.3416\n",
      "Epoch 3/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9226 - accuracy: 0.3419\n",
      "Epoch 4/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9104 - accuracy: 0.3412\n",
      "Epoch 5/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.8984 - accuracy: 0.3455\n",
      "Epoch 6/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.8900 - accuracy: 0.3465\n",
      "Epoch 7/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.8847 - accuracy: 0.3467\n",
      "Epoch 8/10\n",
      "5096/5096 [==============================] - 16s 3ms/step - loss: 1.8774 - accuracy: 0.3486\n",
      "Epoch 9/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.8677 - accuracy: 0.3498\n",
      "Epoch 10/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.8589 - accuracy: 0.3515\n",
      "2548/2548 [==============================] - 3s 1ms/step\n",
      "Epoch 1/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 2.0330 - accuracy: 0.3172\n",
      "Epoch 2/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9457 - accuracy: 0.3420\n",
      "Epoch 3/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9219 - accuracy: 0.3434\n",
      "Epoch 4/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9057 - accuracy: 0.3439\n",
      "Epoch 5/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.8940 - accuracy: 0.3453\n",
      "Epoch 6/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.8776 - accuracy: 0.3490\n",
      "Epoch 7/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.8652 - accuracy: 0.3510\n",
      "Epoch 8/10\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.8610 - accuracy: 0.3516\n",
      "Epoch 9/10\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.8555 - accuracy: 0.3525\n",
      "Epoch 10/10\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.8496 - accuracy: 0.3534\n",
      "2548/2548 [==============================] - 3s 1ms/step\n",
      "Epoch 1/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 20.1427 - accuracy: 0.0955\n",
      "Epoch 2/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 19.6417 - accuracy: 0.0923\n",
      "Epoch 3/10\n",
      "25479/25479 [==============================] - 58s 2ms/step - loss: 19.8984 - accuracy: 0.0919\n",
      "Epoch 4/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 19.8353 - accuracy: 0.0940\n",
      "Epoch 5/10\n",
      "25479/25479 [==============================] - 57s 2ms/step - loss: 20.0467 - accuracy: 0.0958\n",
      "Epoch 6/10\n",
      "25479/25479 [==============================] - 54s 2ms/step - loss: 20.1517 - accuracy: 0.0962\n",
      "Epoch 7/10\n",
      "25479/25479 [==============================] - 54s 2ms/step - loss: 19.8425 - accuracy: 0.0934\n",
      "Epoch 8/10\n",
      "25479/25479 [==============================] - 54s 2ms/step - loss: 20.1423 - accuracy: 0.0955\n",
      "Epoch 9/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 20.0052 - accuracy: 0.0946\n",
      "Epoch 10/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 20.1829 - accuracy: 0.0963\n",
      "12740/12740 [==============================] - 10s 777us/step\n",
      "Epoch 1/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 19.5303 - accuracy: 0.0916\n",
      "Epoch 2/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 19.4230 - accuracy: 0.0912\n",
      "Epoch 3/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 19.5654 - accuracy: 0.0921\n",
      "Epoch 4/10\n",
      "25479/25479 [==============================] - 54s 2ms/step - loss: 19.6711 - accuracy: 0.0938\n",
      "Epoch 5/10\n",
      "25479/25479 [==============================] - 54s 2ms/step - loss: 19.4072 - accuracy: 0.0912\n",
      "Epoch 6/10\n",
      "25479/25479 [==============================] - 54s 2ms/step - loss: 19.4127 - accuracy: 0.0912\n",
      "Epoch 7/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 19.6572 - accuracy: 0.0919\n",
      "Epoch 8/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 19.7760 - accuracy: 0.0931\n",
      "Epoch 9/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 19.4797 - accuracy: 0.0913\n",
      "Epoch 10/10\n",
      "25479/25479 [==============================] - 54s 2ms/step - loss: 19.5509 - accuracy: 0.0929\n",
      "12740/12740 [==============================] - 10s 817us/step\n",
      "Epoch 1/10\n",
      "25479/25479 [==============================] - 58s 2ms/step - loss: 20.0688 - accuracy: 0.0947\n",
      "Epoch 2/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 19.8499 - accuracy: 0.0939\n",
      "Epoch 3/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 19.5897 - accuracy: 0.0930\n",
      "Epoch 4/10\n",
      "25479/25479 [==============================] - 54s 2ms/step - loss: 19.7860 - accuracy: 0.0933\n",
      "Epoch 5/10\n",
      "25479/25479 [==============================] - 54s 2ms/step - loss: 19.7044 - accuracy: 0.0936\n",
      "Epoch 6/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 19.8758 - accuracy: 0.0940\n",
      "Epoch 7/10\n",
      "25479/25479 [==============================] - 54s 2ms/step - loss: 19.7558 - accuracy: 0.0937\n",
      "Epoch 8/10\n",
      "25479/25479 [==============================] - 54s 2ms/step - loss: 19.8261 - accuracy: 0.0945\n",
      "Epoch 9/10\n",
      "25479/25479 [==============================] - 54s 2ms/step - loss: 19.7341 - accuracy: 0.0923\n",
      "Epoch 10/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 19.8832 - accuracy: 0.0941\n",
      "12740/12740 [==============================] - 10s 819us/step\n",
      "Epoch 1/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 225.8432 - accuracy: 0.1960\n",
      "Epoch 2/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 222.3070 - accuracy: 0.1999\n",
      "Epoch 3/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 227.2739 - accuracy: 0.1986\n",
      "Epoch 4/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 224.9395 - accuracy: 0.1996\n",
      "Epoch 5/10\n",
      "25479/25479 [==============================] - 57s 2ms/step - loss: 223.2708 - accuracy: 0.2002\n",
      "Epoch 6/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 222.2059 - accuracy: 0.1996\n",
      "Epoch 7/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 226.1048 - accuracy: 0.1985\n",
      "Epoch 8/10\n",
      "25479/25479 [==============================] - 57s 2ms/step - loss: 225.3945 - accuracy: 0.1996\n",
      "Epoch 9/10\n",
      "25479/25479 [==============================] - 57s 2ms/step - loss: 217.5882 - accuracy: 0.1989\n",
      "Epoch 10/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 224.6839 - accuracy: 0.1992\n",
      "12740/12740 [==============================] - 10s 801us/step\n",
      "Epoch 1/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 188.0739 - accuracy: 0.1954\n",
      "Epoch 2/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 193.3909 - accuracy: 0.1958\n",
      "Epoch 3/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 189.4657 - accuracy: 0.1965\n",
      "Epoch 4/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 187.9893 - accuracy: 0.1959\n",
      "Epoch 5/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 189.5925 - accuracy: 0.1955\n",
      "Epoch 6/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 194.3233 - accuracy: 0.1956\n",
      "Epoch 7/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 192.3532 - accuracy: 0.1972\n",
      "Epoch 8/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 188.8991 - accuracy: 0.1962\n",
      "Epoch 9/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 188.8671 - accuracy: 0.1966\n",
      "Epoch 10/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 185.9577 - accuracy: 0.1982\n",
      "12740/12740 [==============================] - 10s 793us/step\n",
      "Epoch 1/10\n",
      "25479/25479 [==============================] - 54s 2ms/step - loss: 212.4160 - accuracy: 0.1935\n",
      "Epoch 2/10\n",
      "25479/25479 [==============================] - 54s 2ms/step - loss: 203.2683 - accuracy: 0.1971\n",
      "Epoch 3/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 202.8325 - accuracy: 0.1993\n",
      "Epoch 4/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 203.6101 - accuracy: 0.1986\n",
      "Epoch 5/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 202.8246 - accuracy: 0.1976\n",
      "Epoch 6/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 201.4494 - accuracy: 0.1986\n",
      "Epoch 7/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 205.3990 - accuracy: 0.1986\n",
      "Epoch 8/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 200.4589 - accuracy: 0.1974\n",
      "Epoch 9/10\n",
      "25479/25479 [==============================] - 55s 2ms/step - loss: 207.6128 - accuracy: 0.1979\n",
      "Epoch 10/10\n",
      "25479/25479 [==============================] - 56s 2ms/step - loss: 200.1082 - accuracy: 0.1984\n",
      "12740/12740 [==============================] - 10s 799us/step\n",
      "Epoch 1/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 2.0015 - accuracy: 0.4660\n",
      "Epoch 2/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 3/20\n",
      "5096/5096 [==============================] - 16s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 4/20\n",
      "5096/5096 [==============================] - 16s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 5/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 6/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 7/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 8/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 9/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 10/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 11/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 12/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 13/20\n",
      "5096/5096 [==============================] - 16s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 14/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 15/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 16/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 17/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 18/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 19/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "Epoch 20/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9813 - accuracy: 0.4661\n",
      "2548/2548 [==============================] - 3s 1ms/step\n",
      "Epoch 1/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 2.0108 - accuracy: 0.4650\n",
      "Epoch 2/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 3/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 4/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 5/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 6/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 7/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 8/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 9/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 10/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 11/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 12/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 13/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 14/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 15/20\n",
      "5096/5096 [==============================] - 16s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 16/20\n",
      "5096/5096 [==============================] - 16s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 17/20\n",
      "5096/5096 [==============================] - 21s 4ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 18/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 19/20\n",
      "5096/5096 [==============================] - 33s 6ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "Epoch 20/20\n",
      "5096/5096 [==============================] - 36s 7ms/step - loss: 1.9858 - accuracy: 0.4651\n",
      "2548/2548 [==============================] - 3s 1ms/step\n",
      "Epoch 1/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 2.0176 - accuracy: 0.4652\n",
      "Epoch 2/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 3/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 4/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 5/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 6/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 7/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 8/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 9/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 10/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 11/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 12/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 13/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 14/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 15/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 16/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 17/20\n",
      "5096/5096 [==============================] - 14s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 18/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 19/20\n",
      "5096/5096 [==============================] - 15s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "Epoch 20/20\n",
      "5096/5096 [==============================] - 17s 3ms/step - loss: 1.9833 - accuracy: 0.4653\n",
      "2548/2548 [==============================] - 3s 1ms/step\n",
      "Epoch 1/20\n",
      "7644/7644 [==============================] - 23s 3ms/step - loss: 19.0632 - accuracy: 0.0248\n",
      "Epoch 2/20\n",
      "7644/7644 [==============================] - 23s 3ms/step - loss: 9.3461 - accuracy: 0.0341\n",
      "Epoch 3/20\n",
      "7644/7644 [==============================] - 23s 3ms/step - loss: 8.0525 - accuracy: 0.0296\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7644/7644 [==============================] - 22s 3ms/step - loss: 7.9720 - accuracy: 0.0275\n",
      "Epoch 5/20\n",
      "7644/7644 [==============================] - 22s 3ms/step - loss: 8.0521 - accuracy: 0.0272\n",
      "Epoch 6/20\n",
      "7644/7644 [==============================] - 21s 3ms/step - loss: 9.3620 - accuracy: 0.0283\n",
      "Epoch 7/20\n",
      "7644/7644 [==============================] - 22s 3ms/step - loss: 8.0196 - accuracy: 0.0277\n",
      "Epoch 8/20\n",
      "7644/7644 [==============================] - 28s 4ms/step - loss: 8.0815 - accuracy: 0.0266\n",
      "Epoch 9/20\n",
      "7644/7644 [==============================] - 27s 3ms/step - loss: 7.9630 - accuracy: 0.0240\n",
      "Epoch 10/20\n",
      "7644/7644 [==============================] - 27s 3ms/step - loss: 8.2933 - accuracy: 0.0240\n",
      "Epoch 11/20\n",
      "7644/7644 [==============================] - 22s 3ms/step - loss: 9.3947 - accuracy: 0.0215\n",
      "Epoch 12/20\n",
      "7644/7644 [==============================] - 21s 3ms/step - loss: 8.0745 - accuracy: 0.0168\n",
      "Epoch 13/20\n",
      "7644/7644 [==============================] - 21s 3ms/step - loss: 7.8858 - accuracy: 0.0188\n",
      "Epoch 14/20\n",
      "7644/7644 [==============================] - 22s 3ms/step - loss: 7.8937 - accuracy: 0.0200\n",
      "Epoch 15/20\n",
      "7644/7644 [==============================] - 25s 3ms/step - loss: 7.8855 - accuracy: 0.0205\n",
      "Epoch 16/20\n",
      "7644/7644 [==============================] - 21s 3ms/step - loss: 7.8816 - accuracy: 0.0193\n",
      "Epoch 17/20\n",
      "7644/7644 [==============================] - 21s 3ms/step - loss: 7.8601 - accuracy: 0.0199\n",
      "Epoch 18/20\n",
      "7644/7644 [==============================] - 21s 3ms/step - loss: 7.9261 - accuracy: 0.0160\n",
      "Epoch 19/20\n",
      "7644/7644 [==============================] - 21s 3ms/step - loss: 7.9164 - accuracy: 0.0153\n",
      "Epoch 20/20\n",
      "7644/7644 [==============================] - 22s 3ms/step - loss: 10.4195 - accuracy: 0.0162\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=KerasRegressor(build_fn=&lt;function createModel at 0x7f65d444cee0&gt;),\n",
       "                   param_distributions={&#x27;batch_size&#x27;: array([ 10,  50, 100]),\n",
       "                                        &#x27;epochs&#x27;: array([10, 20]),\n",
       "                                        &#x27;model__activation&#x27;: [&#x27;relu&#x27;,\n",
       "                                                              &#x27;sigmoid&#x27;],\n",
       "                                        &#x27;model__learningRate&#x27;: array([0.1 , 0.01, 1.  ]),\n",
       "                                        &#x27;model__loss&#x27;: [&#x27;mean_squared_logarithmic_error&#x27;,\n",
       "                                                        &#x27;mean_squared_error&#x27;,\n",
       "                                                        &#x27;mean_absolute_error&#x27;]},\n",
       "                   verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=KerasRegressor(build_fn=&lt;function createModel at 0x7f65d444cee0&gt;),\n",
       "                   param_distributions={&#x27;batch_size&#x27;: array([ 10,  50, 100]),\n",
       "                                        &#x27;epochs&#x27;: array([10, 20]),\n",
       "                                        &#x27;model__activation&#x27;: [&#x27;relu&#x27;,\n",
       "                                                              &#x27;sigmoid&#x27;],\n",
       "                                        &#x27;model__learningRate&#x27;: array([0.1 , 0.01, 1.  ]),\n",
       "                                        &#x27;model__loss&#x27;: [&#x27;mean_squared_logarithmic_error&#x27;,\n",
       "                                                        &#x27;mean_squared_error&#x27;,\n",
       "                                                        &#x27;mean_absolute_error&#x27;]},\n",
       "                   verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>KerasRegressor(\n",
       "\tmodel=None\n",
       "\tbuild_fn=&lt;function createModel at 0x7f65d444cee0&gt;\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=1\n",
       ")</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>KerasRegressor(\n",
       "\tmodel=None\n",
       "\tbuild_fn=&lt;function createModel at 0x7f65d444cee0&gt;\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=1\n",
       ")</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=KerasRegressor(build_fn=<function createModel at 0x7f65d444cee0>),\n",
       "                   param_distributions={'batch_size': array([ 10,  50, 100]),\n",
       "                                        'epochs': array([10, 20]),\n",
       "                                        'model__activation': ['relu',\n",
       "                                                              'sigmoid'],\n",
       "                                        'model__learningRate': array([0.1 , 0.01, 1.  ]),\n",
       "                                        'model__loss': ['mean_squared_logarithmic_error',\n",
       "                                                        'mean_squared_error',\n",
       "                                                        'mean_absolute_error']},\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestModel.fit(XTrainScaled, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fb3c87b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KerasRegressor(\n",
       "\tmodel=None\n",
       "\tbuild_fn=&lt;function createModel at 0x7f65d444cee0&gt;\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=50\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=20\n",
       "\tmodel__loss=mean_squared_error\n",
       "\tmodel__learningRate=0.01\n",
       "\tmodel__activation=relu\n",
       ")</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>KerasRegressor(\n",
       "\tmodel=None\n",
       "\tbuild_fn=&lt;function createModel at 0x7f65d444cee0&gt;\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=50\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=20\n",
       "\tmodel__loss=mean_squared_error\n",
       "\tmodel__learningRate=0.01\n",
       "\tmodel__activation=relu\n",
       ")</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KerasRegressor(\n",
       "\tmodel=None\n",
       "\tbuild_fn=<function createModel at 0x7f65d444cee0>\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=50\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=20\n",
       "\tmodel__loss=mean_squared_error\n",
       "\tmodel__learningRate=0.01\n",
       "\tmodel__activation=relu\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tunedNN = bestModel.best_estimator_\n",
    "tunedNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1294bcfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2750273936908877"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestModel.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc0b4a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([297.17978605, 286.88663371, 292.3755451 , 559.64894772,\n",
       "        144.68660466, 173.09685755, 148.63535778, 554.12388714,\n",
       "        556.3929321 , 323.5685273 ]),\n",
       " 'std_fit_time': array([18.3143848 ,  2.23915228, 21.2446483 ,  7.13677238,  0.77415385,\n",
       "         1.05312969,  1.66271529,  6.24163712,  3.90453743, 41.55548141]),\n",
       " 'mean_score_time': array([ 3.1051542 ,  2.95088784,  2.85012587, 14.74872017,  3.62145011,\n",
       "         1.89247719,  3.79672662, 11.45707583, 14.40437404,  3.72881969]),\n",
       " 'std_score_time': array([0.09268735, 0.08853294, 0.04719489, 4.118017  , 1.09672168,\n",
       "        0.03200071, 0.97643142, 0.22272141, 4.3348484 , 1.02421738]),\n",
       " 'param_model__loss': masked_array(data=['mean_squared_logarithmic_error',\n",
       "                    'mean_squared_logarithmic_error', 'mean_squared_error',\n",
       "                    'mean_squared_error', 'mean_absolute_error',\n",
       "                    'mean_absolute_error', 'mean_absolute_error',\n",
       "                    'mean_squared_error', 'mean_squared_error',\n",
       "                    'mean_squared_logarithmic_error'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_model__learningRate': masked_array(data=[1.0, 0.01, 0.01, 0.01, 1.0, 0.01, 0.01, 0.1, 1.0, 1.0],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_model__activation': masked_array(data=['sigmoid', 'sigmoid', 'relu', 'sigmoid', 'relu',\n",
       "                    'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'relu'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_epochs': masked_array(data=[20, 20, 20, 10, 10, 20, 10, 10, 10, 20],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_batch_size': masked_array(data=[50, 50, 50, 10, 50, 100, 50, 10, 10, 50],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'model__loss': 'mean_squared_logarithmic_error',\n",
       "   'model__learningRate': 1.0,\n",
       "   'model__activation': 'sigmoid',\n",
       "   'epochs': 20,\n",
       "   'batch_size': 50},\n",
       "  {'model__loss': 'mean_squared_logarithmic_error',\n",
       "   'model__learningRate': 0.01,\n",
       "   'model__activation': 'sigmoid',\n",
       "   'epochs': 20,\n",
       "   'batch_size': 50},\n",
       "  {'model__loss': 'mean_squared_error',\n",
       "   'model__learningRate': 0.01,\n",
       "   'model__activation': 'relu',\n",
       "   'epochs': 20,\n",
       "   'batch_size': 50},\n",
       "  {'model__loss': 'mean_squared_error',\n",
       "   'model__learningRate': 0.01,\n",
       "   'model__activation': 'sigmoid',\n",
       "   'epochs': 10,\n",
       "   'batch_size': 10},\n",
       "  {'model__loss': 'mean_absolute_error',\n",
       "   'model__learningRate': 1.0,\n",
       "   'model__activation': 'relu',\n",
       "   'epochs': 10,\n",
       "   'batch_size': 50},\n",
       "  {'model__loss': 'mean_absolute_error',\n",
       "   'model__learningRate': 0.01,\n",
       "   'model__activation': 'sigmoid',\n",
       "   'epochs': 20,\n",
       "   'batch_size': 100},\n",
       "  {'model__loss': 'mean_absolute_error',\n",
       "   'model__learningRate': 0.01,\n",
       "   'model__activation': 'sigmoid',\n",
       "   'epochs': 10,\n",
       "   'batch_size': 50},\n",
       "  {'model__loss': 'mean_squared_error',\n",
       "   'model__learningRate': 0.1,\n",
       "   'model__activation': 'sigmoid',\n",
       "   'epochs': 10,\n",
       "   'batch_size': 10},\n",
       "  {'model__loss': 'mean_squared_error',\n",
       "   'model__learningRate': 1.0,\n",
       "   'model__activation': 'sigmoid',\n",
       "   'epochs': 10,\n",
       "   'batch_size': 10},\n",
       "  {'model__loss': 'mean_squared_logarithmic_error',\n",
       "   'model__learningRate': 1.0,\n",
       "   'model__activation': 'relu',\n",
       "   'epochs': 20,\n",
       "   'batch_size': 50}],\n",
       " 'split0_test_score': array([-2.16039097e+05, -4.94313539e+00,  2.68070910e-01,  2.69007238e-01,\n",
       "        -2.31801470e-02,  1.36862602e-01,  1.42317990e-01, -2.03542345e+00,\n",
       "        -2.88292361e+00, -2.44943682e+13]),\n",
       " 'split1_test_score': array([-2.20784198e+05, -8.52516224e+00,  2.77267430e-01,  1.72689541e-01,\n",
       "        -6.93384875e-02,  1.49230255e-01,  1.51623486e-01, -1.18474033e+00,\n",
       "        -4.29038471e+01, -7.50073686e+13]),\n",
       " 'split2_test_score': array([-1.38144647e+05, -3.23637078e+00,  2.79743841e-01, -3.97974231e-02,\n",
       "        -2.02183671e-01,  1.42660488e-01,  1.23016163e-01, -1.05025103e-01,\n",
       "        -1.06771917e+01, -2.86496189e+12]),\n",
       " 'mean_test_score': array([-1.91655981e+05, -5.56822281e+00,  2.75027394e-01,  1.33966452e-01,\n",
       "        -9.82341017e-02,  1.42917782e-01,  1.38985880e-01, -1.10839630e+00,\n",
       "        -1.88213208e+01, -3.41222329e+13]),\n",
       " 'std_test_score': array([3.78877827e+04, 2.20391765e+00, 5.02179578e-03, 1.29008237e-01,\n",
       "        7.58805322e-02, 5.05234990e-03, 1.19141921e-02, 7.89928586e-01,\n",
       "        1.73236584e+01, 3.02286128e+13]),\n",
       " 'rank_test_score': array([ 9,  7,  1,  4,  5,  2,  3,  6,  8, 10], dtype=int32)}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestModel.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "72d90efd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__loss': 'mean_squared_error',\n",
       " 'model__learningRate': 0.01,\n",
       " 'model__activation': 'relu',\n",
       " 'epochs': 20,\n",
       " 'batch_size': 50}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestModel.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d539bf01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_model__loss</th>\n",
       "      <th>param_model__learningRate</th>\n",
       "      <th>param_model__activation</th>\n",
       "      <th>param_epochs</th>\n",
       "      <th>param_batch_size</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>297.179786</td>\n",
       "      <td>18.314385</td>\n",
       "      <td>3.105154</td>\n",
       "      <td>0.092687</td>\n",
       "      <td>mean_squared_logarithmic_error</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>{'model__loss': 'mean_squared_logarithmic_erro...</td>\n",
       "      <td>-2.160391e+05</td>\n",
       "      <td>-2.207842e+05</td>\n",
       "      <td>-1.381446e+05</td>\n",
       "      <td>-1.916560e+05</td>\n",
       "      <td>3.788778e+04</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>286.886634</td>\n",
       "      <td>2.239152</td>\n",
       "      <td>2.950888</td>\n",
       "      <td>0.088533</td>\n",
       "      <td>mean_squared_logarithmic_error</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>{'model__loss': 'mean_squared_logarithmic_erro...</td>\n",
       "      <td>-4.943135e+00</td>\n",
       "      <td>-8.525162e+00</td>\n",
       "      <td>-3.236371e+00</td>\n",
       "      <td>-5.568223e+00</td>\n",
       "      <td>2.203918e+00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>292.375545</td>\n",
       "      <td>21.244648</td>\n",
       "      <td>2.850126</td>\n",
       "      <td>0.047195</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>0.01</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>{'model__loss': 'mean_squared_error', 'model__...</td>\n",
       "      <td>2.680709e-01</td>\n",
       "      <td>2.772674e-01</td>\n",
       "      <td>2.797438e-01</td>\n",
       "      <td>2.750274e-01</td>\n",
       "      <td>5.021796e-03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>559.648948</td>\n",
       "      <td>7.136772</td>\n",
       "      <td>14.748720</td>\n",
       "      <td>4.118017</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'model__loss': 'mean_squared_error', 'model__...</td>\n",
       "      <td>2.690072e-01</td>\n",
       "      <td>1.726895e-01</td>\n",
       "      <td>-3.979742e-02</td>\n",
       "      <td>1.339665e-01</td>\n",
       "      <td>1.290082e-01</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>144.686605</td>\n",
       "      <td>0.774154</td>\n",
       "      <td>3.621450</td>\n",
       "      <td>1.096722</td>\n",
       "      <td>mean_absolute_error</td>\n",
       "      <td>1.0</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'model__loss': 'mean_absolute_error', 'model_...</td>\n",
       "      <td>-2.318015e-02</td>\n",
       "      <td>-6.933849e-02</td>\n",
       "      <td>-2.021837e-01</td>\n",
       "      <td>-9.823410e-02</td>\n",
       "      <td>7.588053e-02</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>173.096858</td>\n",
       "      <td>1.053130</td>\n",
       "      <td>1.892477</td>\n",
       "      <td>0.032001</td>\n",
       "      <td>mean_absolute_error</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>{'model__loss': 'mean_absolute_error', 'model_...</td>\n",
       "      <td>1.368626e-01</td>\n",
       "      <td>1.492303e-01</td>\n",
       "      <td>1.426605e-01</td>\n",
       "      <td>1.429178e-01</td>\n",
       "      <td>5.052350e-03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>148.635358</td>\n",
       "      <td>1.662715</td>\n",
       "      <td>3.796727</td>\n",
       "      <td>0.976431</td>\n",
       "      <td>mean_absolute_error</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'model__loss': 'mean_absolute_error', 'model_...</td>\n",
       "      <td>1.423180e-01</td>\n",
       "      <td>1.516235e-01</td>\n",
       "      <td>1.230162e-01</td>\n",
       "      <td>1.389859e-01</td>\n",
       "      <td>1.191419e-02</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>554.123887</td>\n",
       "      <td>6.241637</td>\n",
       "      <td>11.457076</td>\n",
       "      <td>0.222721</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>0.1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'model__loss': 'mean_squared_error', 'model__...</td>\n",
       "      <td>-2.035423e+00</td>\n",
       "      <td>-1.184740e+00</td>\n",
       "      <td>-1.050251e-01</td>\n",
       "      <td>-1.108396e+00</td>\n",
       "      <td>7.899286e-01</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>556.392932</td>\n",
       "      <td>3.904537</td>\n",
       "      <td>14.404374</td>\n",
       "      <td>4.334848</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'model__loss': 'mean_squared_error', 'model__...</td>\n",
       "      <td>-2.882924e+00</td>\n",
       "      <td>-4.290385e+01</td>\n",
       "      <td>-1.067719e+01</td>\n",
       "      <td>-1.882132e+01</td>\n",
       "      <td>1.732366e+01</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>323.568527</td>\n",
       "      <td>41.555481</td>\n",
       "      <td>3.728820</td>\n",
       "      <td>1.024217</td>\n",
       "      <td>mean_squared_logarithmic_error</td>\n",
       "      <td>1.0</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>{'model__loss': 'mean_squared_logarithmic_erro...</td>\n",
       "      <td>-2.449437e+13</td>\n",
       "      <td>-7.500737e+13</td>\n",
       "      <td>-2.864962e+12</td>\n",
       "      <td>-3.412223e+13</td>\n",
       "      <td>3.022861e+13</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0     297.179786     18.314385         3.105154        0.092687   \n",
       "1     286.886634      2.239152         2.950888        0.088533   \n",
       "2     292.375545     21.244648         2.850126        0.047195   \n",
       "3     559.648948      7.136772        14.748720        4.118017   \n",
       "4     144.686605      0.774154         3.621450        1.096722   \n",
       "5     173.096858      1.053130         1.892477        0.032001   \n",
       "6     148.635358      1.662715         3.796727        0.976431   \n",
       "7     554.123887      6.241637        11.457076        0.222721   \n",
       "8     556.392932      3.904537        14.404374        4.334848   \n",
       "9     323.568527     41.555481         3.728820        1.024217   \n",
       "\n",
       "                param_model__loss param_model__learningRate  \\\n",
       "0  mean_squared_logarithmic_error                       1.0   \n",
       "1  mean_squared_logarithmic_error                      0.01   \n",
       "2              mean_squared_error                      0.01   \n",
       "3              mean_squared_error                      0.01   \n",
       "4             mean_absolute_error                       1.0   \n",
       "5             mean_absolute_error                      0.01   \n",
       "6             mean_absolute_error                      0.01   \n",
       "7              mean_squared_error                       0.1   \n",
       "8              mean_squared_error                       1.0   \n",
       "9  mean_squared_logarithmic_error                       1.0   \n",
       "\n",
       "  param_model__activation param_epochs param_batch_size  \\\n",
       "0                 sigmoid           20               50   \n",
       "1                 sigmoid           20               50   \n",
       "2                    relu           20               50   \n",
       "3                 sigmoid           10               10   \n",
       "4                    relu           10               50   \n",
       "5                 sigmoid           20              100   \n",
       "6                 sigmoid           10               50   \n",
       "7                 sigmoid           10               10   \n",
       "8                 sigmoid           10               10   \n",
       "9                    relu           20               50   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'model__loss': 'mean_squared_logarithmic_erro...      -2.160391e+05   \n",
       "1  {'model__loss': 'mean_squared_logarithmic_erro...      -4.943135e+00   \n",
       "2  {'model__loss': 'mean_squared_error', 'model__...       2.680709e-01   \n",
       "3  {'model__loss': 'mean_squared_error', 'model__...       2.690072e-01   \n",
       "4  {'model__loss': 'mean_absolute_error', 'model_...      -2.318015e-02   \n",
       "5  {'model__loss': 'mean_absolute_error', 'model_...       1.368626e-01   \n",
       "6  {'model__loss': 'mean_absolute_error', 'model_...       1.423180e-01   \n",
       "7  {'model__loss': 'mean_squared_error', 'model__...      -2.035423e+00   \n",
       "8  {'model__loss': 'mean_squared_error', 'model__...      -2.882924e+00   \n",
       "9  {'model__loss': 'mean_squared_logarithmic_erro...      -2.449437e+13   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0      -2.207842e+05      -1.381446e+05    -1.916560e+05    3.788778e+04   \n",
       "1      -8.525162e+00      -3.236371e+00    -5.568223e+00    2.203918e+00   \n",
       "2       2.772674e-01       2.797438e-01     2.750274e-01    5.021796e-03   \n",
       "3       1.726895e-01      -3.979742e-02     1.339665e-01    1.290082e-01   \n",
       "4      -6.933849e-02      -2.021837e-01    -9.823410e-02    7.588053e-02   \n",
       "5       1.492303e-01       1.426605e-01     1.429178e-01    5.052350e-03   \n",
       "6       1.516235e-01       1.230162e-01     1.389859e-01    1.191419e-02   \n",
       "7      -1.184740e+00      -1.050251e-01    -1.108396e+00    7.899286e-01   \n",
       "8      -4.290385e+01      -1.067719e+01    -1.882132e+01    1.732366e+01   \n",
       "9      -7.500737e+13      -2.864962e+12    -3.412223e+13    3.022861e+13   \n",
       "\n",
       "   rank_test_score  \n",
       "0                9  \n",
       "1                7  \n",
       "2                1  \n",
       "3                4  \n",
       "4                5  \n",
       "5                2  \n",
       "6                3  \n",
       "7                6  \n",
       "8                8  \n",
       "9               10  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO-DO: Arrange this in a good table format\n",
    "\n",
    "all_results = pd.DataFrame(bestModel.cv_results_)\n",
    "# all_results[\"params_stringified\"] = all_results[\"params\"].applyMap(dictToStr)\n",
    "all_results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56bbfb9d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1911/1911 [==============================] - 2s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "yPred = tunedNN.predict(XTestScaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "33f75ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.6752768 2.770429 2.274855\n"
     ]
    }
   ],
   "source": [
    "# Calculate loss for regression\n",
    "TunedMSEloss = mean_squared_error(yTest, yPred)\n",
    "TunedRMSEloss = mean_squared_error(yTest, yPred, squared=False)\n",
    "TunedMAE = mean_absolute_error(yTest, yPred)\n",
    "\n",
    "print(TunedMSEloss, TunedRMSEloss, TunedMAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b3fc4cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: NN_Model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: NN_Model/assets\n"
     ]
    }
   ],
   "source": [
    "tunedNN.model_.save(\"NN_Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a901c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
